{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a0f151-0e83-432f-93c9-ec6227f6e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 17:01:42.391527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 17:01:43.633949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 17:01:43.634118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 17:01:43.634134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model_name = 'PORT_GRU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978ac49-00af-41c8-92f0-475e701c6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the portuguese words\n",
    "lines= pd.read_table('br-utf8.txt', names=['words'])\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465f2fe-a582-433d-b6ca-47131dfc7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7366950-3e80-4308-88bf-0fe40d49b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines.words = lines.words.apply(lambda x: x.lower())\n",
    "# Remove quotes\n",
    "lines.words = lines.words.apply(lambda x: re.sub(\"'\", '', x))\n",
    "# Add start and end tokens to target sequences\n",
    "lines.words = lines.words.apply(lambda x : '<'+ x + '>')\n",
    "\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbc248-eb1a-4376-acd5-ae4bc44d0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all chars list\n",
    "all_chars=set()\n",
    "for word in lines.words: \n",
    "    for char in word: \n",
    "        if char not in all_chars: all_chars.add(char)\n",
    "        \n",
    "# Word with max lenght\n",
    "max_length_word=0\n",
    "for word in lines.words:\n",
    "    max_length_word = max(len(word), max_length_word)\n",
    "\n",
    "\n",
    "all_chars.add('_')\n",
    "num_chars = len(all_chars) + 1\n",
    "\n",
    "# Dicts to transform chars into index and vice-versa\n",
    "char_token_index = dict([(char, i+1) for i, char in enumerate(all_chars)])\n",
    "reverse_char_token_index = dict((i, char) for char, i in char_token_index.items())\n",
    "\n",
    "# save dictionary to char_to_index.pkl file\n",
    "with open('models/'+model_name+'/char_to_index.pkl', 'wb') as fp:\n",
    "    pickle.dump(char_token_index, fp)\n",
    "    print('Dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bc7f8-2b27-44a6-a22b-cf272a4c6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, __ = train_test_split(lines.words, lines.words, test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2c093-ff89-46ec-a284-4dfc3ed5dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = pd.Series(['<start_>', '<_end>'])\n",
    "X_train = pd.concat([X_train, flags], axis=0)\n",
    "y_train, y_test = X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3499a91-5a02-46e1-8065-f85175830b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size=128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        # iterate from batch to batch\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_word),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_word),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_word, num_chars),dtype='float32')\n",
    "            # get the batch elements \n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, char in enumerate(input_text):\n",
    "                    encoder_input_data[i, t] = char_token_index[char] # encoder input seq\n",
    "                for t, char in enumerate(target_text):\n",
    "                    if t < len(target_text) - 1:\n",
    "                        decoder_input_data[i, t] = char_token_index[char] # decoder input seq\n",
    "                    if t > 0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t-1, char_token_index[char]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a6cb7-1270-48b4-be4b-4611c5dd0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_emb =  Embedding(num_chars, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_gru = GRU(latent_dim, return_state=True)\n",
    "encoder_outputs, encoder_state = encoder_gru(encoder_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5e365-ef4b-4a18-ad8f-dc21dd435cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_emb_layer = Embedding(num_chars, latent_dim, mask_zero = True)\n",
    "decoder_emb = decoder_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_gru = GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,  _ = decoder_gru(decoder_emb, initial_state=encoder_state)\n",
    "\n",
    "# Use a softmax to generate a probability distribution over the target vocabulary for each time step\n",
    "decoder_dense = Dense(num_chars, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a94385-5597-4249-9ef2-4afefc43a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39be9a-e012-4ebd-928d-168eb20fa000",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618c1dd-bd1a-4ed8-8a1e-b35a4b20f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    generate_batch(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=train_samples//batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n",
    "    validation_steps=val_samples//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3d7d5-6e1d-4e46-9728-4f9bcba9c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/'+model_name+'/por_enc_dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780ed29-a79a-4f84-8d50-f1889180effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eddfc0-9d1b-4c11-a52a-d9b2ba7c8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_state)\n",
    "plot_model(encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30905718-015d-4d90-9a76-f0a91fdbc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input = Input(shape=(latent_dim,))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "decoder_emb2 = decoder_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, decoder_state2 = decoder_gru(decoder_emb2, initial_state=decoder_state_input)\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs, decoder_state_input], [decoder_outputs2, decoder_state2])\n",
    "plot_model(decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ebca5-3018-4564-b7ec-16809d8552a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = char_token_index['<']\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, states_value = decoder_model.predict([target_seq, states_value], verbose=0)\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_char_token_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        # Exit condition: either hit max length or find stop token.\n",
    "        if (sampled_char == '>' or len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4c7b2-f585-4ed1-b2e4-a8349f10d8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "for k in range(15):\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-----------------------------------------')\n",
    "    print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "    print('Actual Marathi Translation:', y_test[k:k+1].values[0])\n",
    "    print('Predicted Marathi Translation:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d481d-dfba-4058-b5f4-b31ef0a2b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = pd.Series(['<nintendo>', '<arretado>', '<estrombofone>','<tankar>', '<_end>'])\n",
    "train_gen = generate_batch(unknown, unknown, batch_size=1)\n",
    "for k in range(len(unknown)):\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('In set: ', unknown[k] in  lines.words.values)\n",
    "    print('Input: ', unknown[k])\n",
    "    print('Output: ', decoded_sentence)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f8bdb-29f7-48a8-bbc9-ecde0fbe866d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df27ca-c87e-496f-91e5-157a7b519c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
