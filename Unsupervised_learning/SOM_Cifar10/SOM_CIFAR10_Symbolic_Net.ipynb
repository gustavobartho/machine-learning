{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Dataset\n",
    "from keras.datasets import cifar10\n",
    "#Modelo\n",
    "from keras.models import Sequential\n",
    "#Camadas \n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "#Atributos da rede\n",
    "from keras import optimizers, losses, regularizers\n",
    "#Ferramentas uteis\n",
    "from keras.utils import to_categorical\n",
    "#Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#Predição\n",
    "\n",
    "#Carrrega uma rede ja treinada\n",
    "from keras.models import load_model\n",
    "\n",
    "#Biblioteca para operar sobre o modelo\n",
    "from keras import models\n",
    "#Salvar os modelos dos SOMs em arquivos\n",
    "import pickle\n",
    "#Visualizacao dos resultados\n",
    "import matplotlib.pyplot as plt\n",
    "#Ferramentas matematicas\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from random import randint\n",
    "from numpy import argmax\n",
    "#Self Organizing Maps(SOMs)\n",
    "from minisom import MiniSom\n",
    "#Ferramentas para pegar a lista de imagens\n",
    "import glob\n",
    "import os\n",
    "import natsort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "class SymbolicLayer:\n",
    "    \n",
    "    def __init__(self, cnn_input_layer, learning_rate = 0.08, sigma = 3):\n",
    "        #cnn_input_layer - numero da camada da CNN da qual sera retirado o feature map de entrada da camada\n",
    "        self.cnn_input_layer = cnn_input_layer \n",
    "        self.learning_rate = learning_rate \n",
    "        self.sigma = sigma\n",
    "        #Variaveis cradas na layerCreate\n",
    "        self.layer_input_size = None #Numero de elementos do feature vector de entrada: 235711\n",
    "        self.soms_num = None #Numero de SOMs na entrada dessa camada: 2\n",
    "        self.soms_sizes = None #Arranjo com as dimensoes de cada SOM: ((10, 10), (15, 15))\n",
    "        self.output_size = None #Arranjo com as dimensoes do SOM de saida: (30, 30)\n",
    "        self.layer_branches = None #Arranjo com cada SOM da camada\n",
    "        self.soms_input_size = None #Tamanho do input de cada SOM - é o mesmo para todas: 2343\n",
    "        self.last_layer_input_size = None #Numero de elementos na entrada do SOM de saida: 4500\n",
    "        self.out_layer = None #SOM de saida\n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------\n",
    "     \n",
    "    def layerCreate(self, layer_input_size, soms_num, soms_sizes, output_size):\n",
    "        self.layer_input_size = layer_input_size\n",
    "        self.output_size = output_size\n",
    "        self. soms_num = soms_num\n",
    "        self.soms_sizes = soms_sizes\n",
    "        \n",
    "        #Criar o arranjo com os SOMs daquela camada\n",
    "        self.layer_branches = []\n",
    "        self.soms_input_size = self.layer_input_size/self.soms_num\n",
    "        for i in range(self.soms_num):\n",
    "            self.layer_branches.append(MiniSom(int(self.soms_sizes[i][0]), int(self.soms_sizes[i][1]), int(self.soms_input_size), self.sigma, self.learning_rate))  \n",
    "         \n",
    "        #Calcular o numero de elementos que entrarão na camada de saida\n",
    "        self.last_layer_input_size = sum(np.prod(som_shape) for som_shape in self.soms_sizes)\n",
    "        \n",
    "        #Criar a camada de saida\n",
    "        self.out_layer = MiniSom(int(self.output_size[0]), int(self.output_size[1]), self.last_layer_input_size, self.sigma, self.learning_rate)\n",
    "    #--------------------------------------------------------------------------\n",
    "        \n",
    "    def layerTrain(self, train_feature_map, trains_per_image=2):\n",
    "        #train_feature_map - Feature map que sera o input da camada\n",
    "        #trains_per_image - Numero de vezes que um mesmo feature map sera usado no treino das SOMs de entrada\n",
    "        \n",
    "        #Dividir o feature map de entrada e treinar cada SOM de entrada com a sua parcela correspondente\n",
    "        layer_input = []\n",
    "        for i in range(self.soms_num):\n",
    "            #print(i, ' ', np.shape(train_feature_map))\n",
    "            feature_map = train_feature_map[int(i*self.soms_input_size):int((i+1)*self.soms_input_size)]\n",
    "            #print(np.shape(feature_map))\n",
    "            feature_map = feature_map.reshape(np.prod(np.shape(feature_map)))\n",
    "            self.layer_branches[i].train([feature_map], trains_per_image)\n",
    "            layer_input.append(np.reshape( self.layer_branches[i].activate(feature_map), (int(self.soms_sizes[i][0])*int(self.soms_sizes[i][1]))))\n",
    "            \n",
    "        #Concatenar a saida gerada pelas SOMs de entrada e linearizar\n",
    "        layer_input = np.concatenate(layer_input)\n",
    "        layer_input = np.reshape(layer_input, (1, self.last_layer_input_size))\n",
    "        \n",
    "        #Treina o SOM de saida com o feature vector das SOMs de entrada\n",
    "        self.out_layer.train(layer_input, trains_per_image)\n",
    "        return (self.out_layer.activate(layer_input))\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    def layerGenerateMap(self, feature_map, change=False):\n",
    "        #feature_map - Feature map do qual sera gerado o mapa\n",
    "        \n",
    "        #Separar o feature map entre os SOMs de entrada e gerar os mapas\n",
    "        layer_input = []\n",
    "        for i in range(self.soms_num):\n",
    "            partial_feature_map = feature_map[int(i*self.soms_input_size):int((i+1)*self.soms_input_size)]\n",
    "            partial_feature_map = partial_feature_map.reshape((int(self.soms_input_size)))\n",
    "            layer_input.append(np.reshape( self.layer_branches[i].activate(partial_feature_map), (int(self.soms_sizes[i][0])*int(self.soms_sizes[i][1]))))\n",
    "        \n",
    "        #Concatenar e redimensionar os mapas de saida dos SOMs de entrada\n",
    "        layer_input = np.concatenate(layer_input)\n",
    "        layer_input = np.reshape(layer_input, (1, self.last_layer_input_size))\n",
    "        \n",
    "        #Gerar o mapa de saida\n",
    "        out = self.out_layer.activate(layer_input)\n",
    "        \n",
    "        #Normalizar os dados (0 <= x <= 1), Inverter o mapa (por algum motivo fica melhor), Zerar os valores menores que um limite (tirar interferencia)\n",
    "        f_min, f_max = np.amin(out), np.amax(out)\n",
    "        out = (out - f_min) / (f_max - f_min)\n",
    "        if(change):\n",
    "            out -= 1\n",
    "            for j in range(np.shape(out)[0]):\n",
    "                for k in range(np.shape(out)[1]):\n",
    "                    if(out[j][k] < 0.7): out[j][k] = 0\n",
    "        return out\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    def layerSave(self, layer_path):\n",
    "        #Nome dos arquivos dos SOMs\n",
    "            #SOMs de entrada\n",
    "                #som_in_\"somNum\"_\"somDim\".p\n",
    "                    #somNum - numero daquele SOM na sub layer: 0\n",
    "                    #somDim - uma das dimensoes do SOM: 30\n",
    "            #SOM de saida\n",
    "                #som_out.p\n",
    "\n",
    "        #Iterar pelos SOMs da sub layer e salva los de acordo com o nome definido\n",
    "        som_cont = 0\n",
    "        for som in self.layer_branches:\n",
    "            som_filename = layer_path+\"/somin_\"+str(som_cont)+\"_\"+str(self.soms_sizes[som_cont][0])+\"_.p\"\n",
    "            # saving the som in the file som.p\n",
    "            with open(som_filename, 'wb') as outfile:\n",
    "                pickle.dump(som, outfile)\n",
    "            som_cont += 1\n",
    "\n",
    "        #Salvar o SOM de saida\n",
    "        out_layer_path = layer_path+\"/somout.p\"\n",
    "        with open(out_layer_path, 'wb') as outfile:\n",
    "            pickle.dump(self.out_layer, outfile)\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    def layerLoad(self, layer_path):\n",
    "        #Pegar as informacoes da camada pelo nome da pasta\n",
    "        layer_infos = layer_path.split(\"/\")[-1]\n",
    "        layer_infos = layer_infos.split(\"_\")[2:]\n",
    "        #Definir as variaveis da camada\n",
    "        self.layer_input_size = int(layer_infos[0])\n",
    "        self.output_size = (int(layer_infos[1]), int(layer_infos[1]))\n",
    "        self.soms_num = int(layer_infos[2])\n",
    "               \n",
    "        self.soms_sizes = []\n",
    "        self.layer_branches = []\n",
    "        self.soms_input_size = self.layer_input_size/self.soms_num\n",
    "        \n",
    "        #Pegar os nomes de todos os arquivos na pasta\n",
    "        soms_filenames = []\n",
    "        os.chdir(layer_path+\"/\")\n",
    "        for file_name in glob.glob(\"*.p\"):\n",
    "            file_name = \"/\"+file_name\n",
    "            if(file_name != \"/somout.p\"):\n",
    "                soms_filenames.append(file_name)        \n",
    "        soms_filenames = natsort.natsorted(soms_filenames,reverse=False)\n",
    "\n",
    "        #Carregar todos os SOMs de entrada\n",
    "        for filename in soms_filenames:\n",
    "            infos = filename.split(\"_\")[:-1]\n",
    "            if(infos[0] == \"/somin\"):\n",
    "                with open(layer_path+filename, 'rb') as infile:\n",
    "                    self.layer_branches.append(pickle.load(infile))\n",
    "                    self.soms_sizes.append((int(infos[2]), int(infos[2])))\n",
    "        self.last_layer_input_size = sum(np.prod(som_shape) for som_shape in self.soms_sizes)\n",
    "        \n",
    "        #Carregar o som de saida\n",
    "        with open(layer_path+\"/somout.p\", 'rb') as infile:\n",
    "            self.out_layer = pickle.load(infile)  \n",
    "        \n",
    "        #Retornar as dimensoes dos SOMs para salvar nos parametros da rede\n",
    "        return self.soms_sizes\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "class SymbolicNet:\n",
    "    \n",
    "    def __init__(self, cnn_model, learning_rate = 0.07, sigma = 3):\n",
    "        self.cnn_model = cnn_model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sigma = sigma\n",
    "        #Variaveis cradas na netCreate\n",
    "        self.sub_layer_num = None #Numero de sub layers a serem criadas, cada uma recebendo uma camada da CNN: 3\n",
    "        self.cnn_input_layer = None #Arranjo com os numeros das camadas da CNN das quais serao retiradas as entradas de cada sub layer: (2, 3, 5)\n",
    "             #                                                                                             sub_layer_1      sub_layer_2  sub_layer_3\n",
    "        self.sub_layer_som_num = None #Arranjo com o numero de SOMs em cada sub layer: (2, 1, 1)       -------------------  ---------    --------\n",
    "        self.sub_layer_som_dim = None #Arrando triplo com as dimensoes de cada SOM em cada sub layer: (((15, 15), (10,10)), ((10, 10)), ((20, 20)))\n",
    "        self.out_som_size = None #Arranjo com as dimensoes da saida de cada sub layer: ((7, 7), (5, 5), (8, 8))\n",
    "        self.out_net_dim = None #Dimensoes da saida da rede: (40, 40) \n",
    "        self.activation_model = None #Modelo que ira pegar os feature maps das camadas da CNN selecionadas\n",
    "        self.sub_layer_input_size = None #Numero de elementos na entrada de cada sub layer\n",
    "        self.sub_layer = None #Arranjo com cada sub layer\n",
    "        self.out_layer = None #SOM de saida da rede\n",
    "        \n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    def netCreate(self, sub_layer_num, cnn_input_layer, sub_layer_som_num, sub_layer_som_dim, out_som_size, out_net_dim):\n",
    "        self.sub_layer_num = sub_layer_num\n",
    "        self.cnn_input_layer = cnn_input_layer\n",
    "        self.sub_layer_som_num = sub_layer_som_num\n",
    "        self.sub_layer_som_dim = sub_layer_som_dim\n",
    "        self.out_som_size = out_som_size\n",
    "        self.out_net_dim = out_net_dim\n",
    "        \n",
    "        \n",
    "        #Criar o modelo que pegara as layers da CNN selecionadas\n",
    "        layer_outputs = []\n",
    "        for layer_index in self.cnn_input_layer:\n",
    "            layer_outputs.append(self.cnn_model.layers[layer_index].output)\n",
    "        self.activation_model = models.Model(inputs=model.input, outputs=layer_outputs) \n",
    "        \n",
    "        #Pegar o numero de elementos na entrada de cada sub layer de entrada - numero de elementos na camada da CNN selecionada\n",
    "        self.sub_layer_input_size = []\n",
    "        for layer in self.cnn_input_layer:\n",
    "            cnn_layer_shape = self.cnn_model.layers[layer].output_shape\n",
    "            cnn_layer_size = 1\n",
    "            for layer_dimension in cnn_layer_shape[1:]:\n",
    "                cnn_layer_size *= layer_dimension\n",
    "            self.sub_layer_input_size.append(cnn_layer_size)\n",
    "        \n",
    "        #Criar e inserir cada sub layer de entrada em um arranjo com as sublayer na ordem de entrada \n",
    "        self.sub_layer = []\n",
    "        cont = 0\n",
    "        for input_size in self.sub_layer_input_size:\n",
    "            \n",
    "            #Testar se o numero de SOMs na sub layer é divisisvel pelo tamanho do feature map de entrada e caso não seja aumentar até que se torne divisivel\n",
    "            changed = False\n",
    "            init_value = self.sub_layer_som_num[cont]\n",
    "            while(input_size%self.sub_layer_som_num[cont] != 0):\n",
    "                self.sub_layer_som_num[cont] += 1\n",
    "                changed = True\n",
    "            if(changed): \n",
    "                print(\"Quantidade de SOMs da\", cont+1, \" sub layer alterado de \", init_value, \" para \", self.sub_layer_som_num[cont])\n",
    "                #Adicionar no array de dimensoed dos SOMs daquela subleyer as dimensoes das sublayers criadas\n",
    "                for i in range(self.sub_layer_som_num[cont] - init_value):\n",
    "                    dim = randint(10, 20)\n",
    "                    self.sub_layer_som_dim[cont].append((dim, dim))\n",
    "            aux_sub_layer = SymbolicLayer(self.cnn_input_layer[cont])\n",
    "            aux_sub_layer.layerCreate(input_size, self.sub_layer_som_num[cont], self.sub_layer_som_dim[cont], self.out_som_size[cont])\n",
    "            self.sub_layer.append(aux_sub_layer)\n",
    "            cont+=1\n",
    "            \n",
    "        #Criar o SOM de sida \n",
    "        out_layer_input_size = 0\n",
    "        for sub_layer_shapes in out_som_size:\n",
    "            out_layer_input_size += np.prod(sub_layer_shapes)\n",
    "        self.out_layer = MiniSom(int(out_net_dim[0]), int(out_net_dim[1]), out_layer_input_size, self.sigma, self.learning_rate)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "        \n",
    "    def netTrain(self, training_data, verbose=True, verbose_num=200):\n",
    "        if(verbose): \n",
    "            print(\"INICIO\")\n",
    "            total_training_data = len(training_data)\n",
    "        #training_data - Array com os nomes das imagens nas quais será aplicado os treinamentos\n",
    "        #verbose - Se vai imprimir as informacoes de treino\n",
    "        #verbose_num - Quantidade de imagens por aviso\n",
    "        num = 1\n",
    "        #Tratar as imagens para se adequarem ao input da rede\n",
    "        for image in training_data:\n",
    "            image = np.reshape(image, (1, np.shape(image)[0]  ,np.shape(image)[1], np.shape(image)[2]))\n",
    "            #Passar a imagem pela rede e salvar a ativação das camadas escolhidas \n",
    "            cnn_layer_signal = self.activation_model.predict(image)\n",
    "            \n",
    "            #Treinar cada sub layer com a ativação da sua camada\n",
    "            index = 0\n",
    "            out_layer_input = []\n",
    "            for feature_map in cnn_layer_signal:\n",
    "                feature_map = feature_map.reshape(np.prod(np.shape(feature_map)))\n",
    "                aux_out_layer_input = self.sub_layer[index].layerTrain(feature_map, trains_per_image=10)\n",
    "                aux_out_layer_input = np.reshape(aux_out_layer_input, np.prod(np.shape(aux_out_layer_input)))\n",
    "                out_layer_input.append(aux_out_layer_input)\n",
    "                index += 1\n",
    "                \n",
    "            #Concatenar as saidas de cada sub layer de entrada para criar um feture vector para a sub layer de saida\n",
    "            out_layer_input = np.concatenate(out_layer_input)\n",
    "            \n",
    "            #Treinar a camada de saida com o feature vector gerado\n",
    "            self.out_layer.train([out_layer_input], 1)\n",
    "            if(verbose):\n",
    "                if(num%verbose_num == 0): print(\"Concluido: \", num, \"/\", total_training_data)\n",
    "            num+=1\n",
    "        if(verbose): print(\"FIM\")\n",
    "    #--------------------------------------------------------------------------\n",
    "            \n",
    "    def netGenerateMap(self, image, change=False):\n",
    "        image = np.reshape(image, (1, np.shape(image)[0]  ,np.shape(image)[1], np.shape(image)[2]))\n",
    "        #Passar a imagem pela rede e salvar a ativação das camadas escolhidas \n",
    "        cnn_layer_signal = self.activation_model.predict(image)\n",
    "\n",
    "        #Treinar cada sub layer com a ativação da sua camada\n",
    "        index = 0\n",
    "        out_layer_input = []\n",
    "        for feature_map in cnn_layer_signal:\n",
    "            feature_map = feature_map.reshape(np.prod(np.shape(feature_map)))\n",
    "            aux_out_layer_input = self.sub_layer[index].layerGenerateMap(feature_map)\n",
    "            aux_out_layer_input = np.reshape(aux_out_layer_input, np.prod(np.shape(aux_out_layer_input)))\n",
    "            out_layer_input.append(aux_out_layer_input)\n",
    "            index += 1\n",
    "\n",
    "        #Concatenar as saidas de cada sub layer de entrada para criar um feture vector para a sub layer de saida\n",
    "        out_layer_input = np.concatenate(out_layer_input)\n",
    "\n",
    "        #Treinar a camada de saida com o feature vector gerado\n",
    "        aux_out = self.out_layer.activate(out_layer_input)\n",
    "        f_min, f_max = np.amin(aux_out), np.amax(aux_out)\n",
    "        aux_out = (aux_out - f_min) / (f_max - f_min)\n",
    "        if(change):\n",
    "            aux_out -= 1\n",
    "            for j in range(np.shape(aux_out)[0]):\n",
    "                for k in range(np.shape(aux_out)[1]):\n",
    "                    if(aux_out[j][k] < 0.7): aux_out[j][k] = 0       \n",
    "        return aux_out\n",
    "    #--------------------------------------------------------------------------    \n",
    "\n",
    "    def netSave(self, path, cnn_model):\n",
    "        #Nome da pasta da rede\n",
    "            #net_\"cnnModel\"_\"numSubLayers\"_\"outDim\"\n",
    "                #cnnModel - modelo da CNN usado: VGG19\n",
    "                #numSubLayers - numero de sublayers daquela rede: 3\n",
    "                #outDim - uma das dimensoes de saida da rede: 40\n",
    "\n",
    "        #Nome da pasta da sub_layer\n",
    "            #sub_layer_\"layerNum\"_\"inputSize\"_\"numSoms\"_\"outDim\"_\"inputLayer\"\n",
    "                #layerNum - numero da sublayer: 0\n",
    "                #inputSize - tamanho do feature vector esperado na entrada da sub layer\n",
    "                #numSoms - numero de SOMs daquela sub layer: 3\n",
    "                #outDim - uma das dimensoes de saida da sublayer: 40\n",
    "                #inputLayer - numero da camada da CNN de qual sera retirado o feature map\n",
    "\n",
    "        #Criar a pasta da rede\n",
    "        net_path = path+\"/net_\"+cnn_model+\"_\"+str(simb_net.sub_layer_num)+\"_\"+str(self.out_net_dim[0])\n",
    "        if not os.path.exists(net_path):\n",
    "            os.makedirs(net_path)\n",
    "\n",
    "        #Criar a pasta de cada sub layer de acordo com o nome e salvar\n",
    "        sub_layer_cont = 0\n",
    "        for sub_layer in simb_net.sub_layer:\n",
    "            sub_layer_path = net_path+\"/sublayer_\"+str(sub_layer_cont)+\"_\"+str(self.sub_layer_input_size[sub_layer_cont])+\"_\"+str(self.out_som_size[sub_layer_cont][0])+\"_\"+str(self.sub_layer_som_num[sub_layer_cont])+\"_\"+str(self.cnn_input_layer[sub_layer_cont])\n",
    "            if not os.path.exists(sub_layer_path):\n",
    "                os.makedirs(sub_layer_path)\n",
    "            sub_layer.layerSave(sub_layer_path)\n",
    "            sub_layer_cont += 1\n",
    "\n",
    "        #Salvar o SOM de saida da rede\n",
    "        out_som_filename = net_path+\"/somout.p\"\n",
    "        with open(out_som_filename, 'wb') as outfile:\n",
    "                pickle.dump(simb_net.out_layer, outfile)\n",
    "    #--------------------------------------------------------------------------    \n",
    "    \n",
    "    def netLoad(self, net_path, cnn_model):\n",
    "        #Criar o modelo que pegara as layers da CNN selecionadas\n",
    "        self.cnn_model = cnn_model\n",
    "        self.sub_layer = []\n",
    "        self.sub_layer_input_size = []\n",
    "        self.out_som_size = []\n",
    "        self.sub_layer_som_num = []\n",
    "        self.cnn_input_layer = []\n",
    "        self.sub_layer_som_dim = []\n",
    "        net_infos = net_path.split(\"/\")[-1]\n",
    "        net_infos = net_infos.split(\"_\")[2:]\n",
    "        self.sub_layer_num = int(net_infos[0])\n",
    "        self.out_net_dim = (int(net_infos[1]), net_infos[1])\n",
    "        #Salvar os nomes das pastas dentro da pasta da rede \n",
    "        os.chdir(net_path)\n",
    "        sub_layers_names = []\n",
    "        for name in os.listdir(\".\"):\n",
    "            if os.path.isdir(name):\n",
    "                sub_layers_names.append(name)\n",
    "        sub_layers_names = natsort.natsorted(sub_layers_names,reverse=False)\n",
    "        #Carrega cada sub layer e salva os parametros da rede de acordo com a rede carregada\n",
    "        for cont in range(self.sub_layer_num):\n",
    "            sub_layers_info = sub_layers_names[cont]\n",
    "            sub_layers_info = sub_layers_info.split(\"_\")[2:]\n",
    "            self.sub_layer_input_size.append(int(sub_layers_info[0]))\n",
    "            self.out_som_size.append((int(sub_layers_info[1]), int(sub_layers_info[1])))\n",
    "            self.sub_layer_som_num.append(int(sub_layers_info[2]))\n",
    "            self.cnn_input_layer.append(int(sub_layers_info[3]))\n",
    "            self.sub_layer_input_size = []\n",
    "            cnn_layer_shape = self.cnn_model.layers[self.cnn_input_layer[cont]].output_shape\n",
    "            cnn_layer_size = 1\n",
    "            for layer_dimension in cnn_layer_shape[1:]:\n",
    "                cnn_layer_size *= layer_dimension\n",
    "            self.sub_layer_input_size.append(cnn_layer_size) \n",
    "            aux_sub_layer = SymbolicLayer(self.cnn_input_layer[cont])\n",
    "            self.sub_layer_som_dim.append(aux_sub_layer.layerLoad(net_path+\"/\"+sub_layers_names[cont]))\n",
    "            self.sub_layer.append(aux_sub_layer)\n",
    "            \n",
    "        layer_outputs = []\n",
    "        for layer_index in self.cnn_input_layer:\n",
    "            layer_outputs.append(self.cnn_model.layers[layer_index].output)\n",
    "        self.activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "                    \n",
    "        with open(net_path+\"/somout.p\", 'rb') as infile:\n",
    "            self.out_layer = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "num_classes = 10\n",
    "decay = 1e-3\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print('X TRAIN: ',x_train.shape)\n",
    "print('Y TRAIN: ',y_train.shape)\n",
    "print('X TEST: ',x_test.shape)\n",
    "print('Y TEST: ',y_test.shape)\n",
    "\n",
    "model = load_model('/home/gustavo/JUPITER-LAB/networks/CNN_59_Cifar10.h5')\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l1_l2(decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l1_l2(decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l1_l2(decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l1_l2(decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l1_l2(decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l1_l2(decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(500, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss=losses.categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
    "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=1, fill_mode='nearest', horizontal_flip=True, vertical_flip=True)\n",
    "datagen.fit(x_train)\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size), epochs=epochs, validation_data=(x_test, y_test), shuffle=True, steps_per_epoch=len(x_train)/batch_size, workers=1)\n",
    "#model.fit(x_train, y_train, batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "model.save('/home/gustavo/JUPITER-LAB/networks/')\n",
    "'''\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=1)\n",
    "#print(\"Test score: \", score[0])\n",
    "#print(\"Test accuracy: \", score[1])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  conv2d_1  -  (None, 32, 32, 32)\n",
      "1  -  activation_1  -  (None, 32, 32, 32)\n",
      "2  -  batch_normalization_1  -  (None, 32, 32, 32)\n",
      "3  -  conv2d_2  -  (None, 32, 32, 32)\n",
      "4  -  activation_2  -  (None, 32, 32, 32)\n",
      "5  -  batch_normalization_2  -  (None, 32, 32, 32)\n",
      "6  -  max_pooling2d_1  -  (None, 16, 16, 32)\n",
      "7  -  dropout_1  -  (None, 16, 16, 32)\n",
      "8  -  conv2d_3  -  (None, 16, 16, 64)\n",
      "9  -  activation_3  -  (None, 16, 16, 64)\n",
      "10  -  batch_normalization_3  -  (None, 16, 16, 64)\n",
      "11  -  conv2d_4  -  (None, 16, 16, 64)\n",
      "12  -  activation_4  -  (None, 16, 16, 64)\n",
      "13  -  batch_normalization_4  -  (None, 16, 16, 64)\n",
      "14  -  max_pooling2d_2  -  (None, 8, 8, 64)\n",
      "15  -  dropout_2  -  (None, 8, 8, 64)\n",
      "16  -  conv2d_5  -  (None, 8, 8, 128)\n",
      "17  -  activation_5  -  (None, 8, 8, 128)\n",
      "18  -  batch_normalization_5  -  (None, 8, 8, 128)\n",
      "19  -  conv2d_6  -  (None, 8, 8, 128)\n",
      "20  -  activation_6  -  (None, 8, 8, 128)\n",
      "21  -  batch_normalization_6  -  (None, 8, 8, 128)\n",
      "22  -  max_pooling2d_3  -  (None, 4, 4, 128)\n",
      "23  -  dropout_3  -  (None, 4, 4, 128)\n",
      "24  -  flatten_1  -  (None, 2048)\n",
      "25  -  dense_1  -  (None, 1000)\n",
      "26  -  dropout_4  -  (None, 1000)\n",
      "27  -  dense_2  -  (None, 500)\n",
      "28  -  dense_3  -  (None, 100)\n",
      "29  -  dropout_5  -  (None, 100)\n",
      "30  -  dense_4  -  (None, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "#Imprime os nomes das camadas do modelo\n",
    "j = 0\n",
    "for i in model.layers:\n",
    "    print(j, ' - ', i.name, \" - \", i.output_shape)\n",
    "    j += 1\n",
    "\n",
    "data = np.concatenate((x_train, x_test))\n",
    "labels = np.concatenate((y_train, y_test))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 15000\n",
    "simb_net = SymbolicNet(model)\n",
    "num_sub_layers = 3\n",
    "cnn_layers_num = (14, 22)\n",
    "sub_layers_som_num = (4, 2)\n",
    "sub_layers_som_shape = (((20,20),(20,20),(20,20),(20,20)), ((15,15),(15,15)))\n",
    "sub_layers_out_shape = ((25, 25), (17, 17))\n",
    "out_shape = (27, 27)\n",
    "\n",
    "simb_net.netCreate(num_sub_layers, cnn_layers_num, sub_layers_som_num, sub_layers_som_shape, sub_layers_out_shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1b1d42d550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(simb_net.netGenerateMap(data[3099]), cmap = 'hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a840726d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(simb_net.netGenerateMap(data[35989]), cmap = 'hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simb_net.netSave(\"/home/gustavo/JUPITER-LAB/networks\", \"Cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fd9a0f6021be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimb_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/gustavo/JUPITER-LAB/networks/net_Cifar10_3_27\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a2a2341b885e>\u001b[0m in \u001b[0;36mnetLoad\u001b[0;34m(self, net_path, cnn_model)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m#Carrega cada sub layer e salva os parametros da rede de acordo com a rede carregada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_layer_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0msub_layers_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_layers_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0msub_layers_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_layers_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_layer_input_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_layers_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "simb_net.netLoad(\"/home/gustavo/JUPITER-LAB/networks/net_Cifar10_3_27\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
