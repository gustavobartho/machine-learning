{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(object):\n",
    "    def __init__ (self, inputShape, filters, latentDim, learning_rate=3e-4):\n",
    "        '''\n",
    "        Inputs:\n",
    "            :param width: (int) -> Width of the input image in pixels.\n",
    "            :param height: (int) -> Height of the input image in pixels.\n",
    "            :param depth: (int) -> Number of channels (i.e., depth) of the input volume.\n",
    "            :param filters: (tuple(int)) -> A tuple that contains the set of filters for convolution operations.\n",
    "            :param latentDim: (int) -> The number of neurons in our fully-connected (Dense) latent vector\n",
    "        '''\n",
    "        self.inputShape = inputShape\n",
    "        self.filters = filters\n",
    "        self.latentDim = latentDim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = Adam(learning_rate)\n",
    "        self.encoder, self.decoder, self.autoencoder = self.create_nets(width, height, depth, filters, latentDim)\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------------       \n",
    "    def create_nets(self, width, height, depth, filters, latentDim):\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        # define the input to the encoder\n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = inputs\n",
    "        # loop over the number of filters\n",
    "        for f in filters:\n",
    "            # apply a CONV => RELU => BN operation\n",
    "            x = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "        # flatten the network and then construct our latent vector\n",
    "        volumeSize = K.int_shape(x)\n",
    "        x = Flatten()(x)\n",
    "        latent = Dense(latentDim)(x)\n",
    "        # build the encoder model\n",
    "        encoder = Model(inputs, latent, name=\"encoder\")\n",
    "\n",
    "        # start building the decoder model which will accept the\n",
    "        # output of the encoder as its inputs\n",
    "        latentInputs = Input(shape=(latentDim,))\n",
    "        x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
    "        x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
    "        # loop over our number of filters again, but this time in\n",
    "        # reverse order\n",
    "        for f in filters[::-1]:\n",
    "            # apply a CONV_TRANSPOSE => RELU => BN operation\n",
    "            x = Conv2DTranspose(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "        # apply a single CONV_TRANSPOSE layer used to recover the\n",
    "        # original depth of the image\n",
    "        x = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
    "        outputs = Activation(\"sigmoid\")(x)\n",
    "        # build the decoder model\n",
    "        decoder = Model(latentInputs, outputs, name=\"decoder\")\n",
    "        # our autoencoder is the encoder + decoder\n",
    "        autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n",
    "        \n",
    "        autoencoder.compile(loss=\"mse\", optimizer=self.optimizer)\n",
    "        # return 3 networks\n",
    "        return encoder, decoder, autoencoder\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def train(self, batch_size, train_data, train_label, num, verbose_num, validation_data, epochs=1):\n",
    "        verbose = 1 if num%verbose_num==0 else 0\n",
    "        validation_data = validation_data if num%verbose_num==0 else None\n",
    "        self.autoencoder.fit(\n",
    "            train_data, \n",
    "            train_label, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            validation_data=validation_data,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def predict(self, input_data):\n",
    "        return self.autoencoder.predict(input_data)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def encode(self, input_data):\n",
    "        return self.encoder.predict(input_data)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def decode(self, input_data):\n",
    "        return self.decoder.predict(input_data)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def save(self, path, name, num):\n",
    "        if not os.path.exists(path+name+'/'):\n",
    "            os.mkdir(path+name+'/')\n",
    "            \n",
    "        path = path+name+'/_'+str(num)+'/'\n",
    "        os.mkdir(path)\n",
    "        \n",
    "        enc_model_json = self.encoder.to_json()\n",
    "        with open(path+'_encoder_'+str(num)+'.json', 'w') as json_file:\n",
    "            json_file.write(enc_model_json)\n",
    "        self.encoder.save_weights(path+'_encoder_'+str(num)+'.h5')\n",
    "        \n",
    "        dec_model_json = self.decoder.to_json()\n",
    "        with open(path+'_decoder_'+str(num)+'.json', 'w') as json_file:\n",
    "            json_file.write(dec_model_json)\n",
    "        self.decoder.save_weights(path+'_decoder_'+str(num)+'.h5')\n",
    "        \n",
    "        aut_model_json = self.autoencoder.to_json()\n",
    "        with open(path+'_autoencoder_'+str(num)+'.json', 'w') as json_file:\n",
    "            json_file.write(aut_model_json)\n",
    "        self.autoencoder.save_weights(path+'_autoencoder_'+str(num)+'.h5')\n",
    "     \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def load(self, path, num):\n",
    "        path = path+'/_'+str(num)+'/'\n",
    "        \n",
    "        enc_json_file = open(path+'_encoder_'+str(num)+'.json', 'r')\n",
    "        enc_loaded_model_json = enc_json_file.read()\n",
    "        enc_json_file.close()\n",
    "        self.encoder = models.model_from_json(enc_loaded_model_json)\n",
    "        self.encoder.load_weights(path+'_encoder_'+str(num)+'.h5')\n",
    "        \n",
    "        dec_json_file = open(path+'_decoder_'+str(num)+'.json', 'r')\n",
    "        dec_loaded_model_json = dec_json_file.read()\n",
    "        dec_json_file.close()\n",
    "        self.decoder = models.model_from_json(dec_loaded_model_json)\n",
    "        self.decoder.load_weights(path+'_decoder_'+str(num)+'.h5')\n",
    "        \n",
    "        aut_json_file = open(path+'_autoencoder_'+str(num)+'.json', 'r')\n",
    "        aut_loaded_model_json = aut_json_file.read()\n",
    "        aut_json_file.close()\n",
    "        self.autoencoder = models.model_from_json(aut_loaded_model_json)\n",
    "        self.autoencoder.load_weights(path+'_autoencoder_'+str(num)+'.h5')\n",
    "        \n",
    "        self.autoencoder.compile(loss=\"mse\", optimizer=self.optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simbolic_Net(object):\n",
    "    def __init__(self):\n",
    "        self.model = VGG19()\n",
    "        self.autoencoders = []\n",
    "        \n",
    "        self.autoencoders.append(ConvAutoencoder(56, 56, 128, (44, 64, 128), 4096))\n",
    "        self.soms.append(MiniSom(32, 32, 4096, 2, 0.03))\n",
    "     \n",
    "        self.autoencoders.append(ConvAutoencoder(28, 28, 43, (64, 128), 2048))\n",
    "        self.soms.append(MiniSom(25, 25, 2048, 1.7, 0.04))\n",
    "        \n",
    "        self.autoencoders.append(ConvAutoencoder(14, 14, 86, (128,), 1024))\n",
    "        self.soms.append(MiniSom(20, 20, 1024, 1.5, 0.05))\n",
    "        \n",
    "        #self.autoencoders.append(ConvAutoencoder(7, 7, 86, (), 500))\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def train(self, epochs, batch_size, images_path, images_names, validation_data, stride, num_comp, pooling_ratio, only_som=False, only_aut=False):\n",
    "        print('INICIO')\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            val_data = self.sens_net.extract_batch(batch_size, images_path, validation_data, stride, num_comp, pooling_ratio)\n",
    "            #Gera o vetor com um batch de ativações ja com dimensões reduzidas\n",
    "            activations  = self.sens_net.extract_batch(batch_size, images_path, images_names, stride, num_comp, pooling_ratio) \n",
    "            for i, _ in enumerate(self.autoencoders):\n",
    "                train_data = np.array([layer[i] for layer in activations])\n",
    "                validation_data_ = np.array([layer[i] for layer in val_data])\n",
    "                \n",
    "                if only_aut or not only_som:\n",
    "                    self.autoencoders[i].train(batch_size, train_data, train_data, epoch, 200, (validation_data_, validation_data_))\n",
    "                \n",
    "                if only_som or not only_aut:\n",
    "                    self.soms[i].train(np.asarray(self.autoencoders[i].encode(train_data)), num_iteration=3)\n",
    "                \n",
    "            print('\\rEpoch: ', epoch+1, '/', epochs, end='')\n",
    "        \n",
    "        print('\\nFIM')\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def generate_maps(self, image_path, image_name, stride, num_comp, pooling_ratio):\n",
    "        data = self.sens_net.extract_batch(len(image_name), images_path, image_name, stride, num_comp, pooling_ratio)\n",
    "        out_data = []\n",
    "        atoenc_data = []\n",
    "        \n",
    "        for i, _ in enumerate(self.autoencoders):\n",
    "            data_aux = np.array([layer[i] for layer in data])\n",
    "            auto_out = self.autoencoders[i].predict(data_aux)\n",
    "            data_aux = self.autoencoders[i].encode(data_aux)\n",
    "            aux=[]\n",
    "            \n",
    "            for act in data_aux:\n",
    "                aux.append(self.soms[i].activate(act))\n",
    "            \n",
    "            atoenc_data.append(auto_out)\n",
    "            out_data.append(aux)\n",
    "            \n",
    "        return out_data, atoenc_data\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def save_net(self, path, name):\n",
    "        for i, _ in enumerate(self.autoencoders):\n",
    "            self.autoencoders[i].save(path, name, i)\n",
    "            with open(path+name+'/_'+str(i)+'/SOM_'+str(i)+'.p', 'wb') as outfile:\n",
    "                pickle.dump(self.soms[i], outfile)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------\n",
    "    def load_net(self, path, som=True):\n",
    "        for i, _ in enumerate(self.autoencoders):\n",
    "            self.autoencoders[i].load(path, i)\n",
    "            if som:\n",
    "                with open(path+'_'+str(i)+'/SOM_'+str(i)+'.p', 'rb') as infile:\n",
    "                    self.soms[i] = pickle.load(infile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
