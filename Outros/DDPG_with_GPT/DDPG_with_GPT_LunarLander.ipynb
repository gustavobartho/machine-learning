{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8WT_0Y-KqQdW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout, BatchNormalization, LayerNormalization, Lambda\n",
        "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vQX1S3qQdc"
      },
      "source": [
        "# Objective: Create a DDPG algorithm with a GPT as the Actor network.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeO6YvRbqQdf",
        "outputId": "98286af3-47a0-4c4a-8c82-c041308ccc0c"
      },
      "outputs": [],
      "source": [
        "#Ornstein-Uhlenbeck Noise \n",
        "class OUActionNoise(object):\n",
        "    def __init__(self, mean, sigma=0.5, theta=0.2, dt=0.4, x0=None):\n",
        "        self.mean = mean\n",
        "        self.sigma = sigma\n",
        "        self.theta = theta\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.reset()\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "    #Method that enables to write classes where the instances behave like functions and can be called like a function.    \n",
        "    def __call__(self):\n",
        "        x = self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
        "        self.x_prev = x\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "    def reset(self):\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mean)\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-n5JPCPqQdi",
        "outputId": "a2773b70-2744-4aa3-c777-6acd96c63981"
      },
      "outputs": [],
      "source": [
        "#Replay Buffer \n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size, batch_size):\n",
        "        '''\n",
        "        Args:\n",
        "            size (integer): The size of the replay buffer.              \n",
        "            batch_size (integer): The batch size.\n",
        "            block_size (integer): \n",
        "        '''\n",
        "        self.buffer = [[]]\n",
        "        self.batch_size = batch_size\n",
        "        self.max_size = size\n",
        "        \n",
        "    #--------------------------------------------------    \n",
        "    def append(self, steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        if self.size >= self.max_size: del self.buffer[0]\n",
        "        for step in steps: self.buffer[-1].append(step)\n",
        "        # if done create new episode entry\n",
        "        # (state, action, reward, done)\n",
        "        if (steps[-1]['done']): self.buffer.append([])\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def clear(self):\n",
        "        self.buffer.clear()\n",
        "    \n",
        "    #--------------------------------------------------    \n",
        "    def getEpisodes(self):\n",
        "        episodes = np.random.choice(\n",
        "            np.arange(self.size - 1), #don't chose the current step\n",
        "            size=(self.batch_size,), \n",
        "            replace=True\n",
        "        )\n",
        "        return  [self.buffer[episode] for episode in episodes]\n",
        "    \n",
        "    #--------------------------------------------------  \n",
        "    @property  \n",
        "    def size(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            Number of elements in the buffer\n",
        "        '''\n",
        "        return len(self.buffer)\n",
        "\n",
        "    #--------------------------------------------------  \n",
        "    @property \n",
        "    def hasMinLength(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            Boolean indicating if the memory have the minimum number of elements or not\n",
        "        '''\n",
        "        return (self.size > 8)\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    @property  \n",
        "    def data(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            List with all the elements in the buffer\n",
        "        '''\n",
        "        return self.buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1en0TDn5qQdl",
        "outputId": "c485ce90-2d8c-4f0a-cc48-6efad0b8233c"
      },
      "outputs": [],
      "source": [
        "gpt_kernel_initializer = lambda: RandomNormal(mean=0.0, stddev=0.1)\n",
        "gpt_bias_initializer = lambda: Zeros()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "vxHdLrUWqQdm"
      },
      "outputs": [],
      "source": [
        "# Individual Head of self-attention\n",
        "class Head(Layer):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, batch_size, block_size, head_size, dropout):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.block_size = block_size\n",
        "\n",
        "        # key, query and value layers\n",
        "        self.key = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "        self.query = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "        self.value = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout_v = Dropout(dropout)\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        state_emb, global_pos_emb, action_emb = inp[0], inp[1], inp[2]\n",
        "        B, T, C = state_emb.shape\n",
        "        if(B is None): B = self.batch_size \n",
        "        if(T is None): T = self.block_size\n",
        "        if(C is None): C = self.state_dim\n",
        "\n",
        "        k = self.key(global_pos_emb)   # (B,T,C)\n",
        "        #q = self.query(state_emb + global_pos_emb) # (B,T,C)\n",
        "        \n",
        "        # compute attention scores (\"affinities\") - C**-0.5 is for normalization\n",
        "        wei =  tf.matmul(k, tf.transpose(k, perm=[0, 2, 1])) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei *= tf.math.rsqrt(tf.cast(C, tf.float32))\n",
        "        wei = tf.where(tf.linalg.band_part(tf.ones((T, T)), -1, 0) == 0, tf.constant(float(\"-inf\"), shape=(B, T, T)), wei) # (B, T, T)\n",
        "        wei = tf.nn.softmax(wei, axis=-1) # (B, T, T)\n",
        "        # perform the weighted aggregation of the values\n",
        "\n",
        "        v = self.value(state_emb) # (B,T,C)\n",
        "        out = tf.matmul(wei, v) # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        out = self.dropout_v(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        #state_emb = global_pos_emb = local_pos_emb = embedding_dim\n",
        "        state_emb, global_pos_emb, action_emb = input_shape\n",
        "        self.value.build(state_emb)\n",
        "        self.key.build(state_emb)\n",
        "        self.query.build(state_emb)\n",
        "        super(Head, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "46rkRg5nqQdn"
      },
      "outputs": [],
      "source": [
        "# Layer with multiple self-attention Heads for data communication \n",
        "class MultiHeadAttention(Layer):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, batch_size, block_size, embedding_dim, num_heads, head_size, dropout):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.heads = []\n",
        "        for _ in range(num_heads):\n",
        "            head = Head(\n",
        "                batch_size=batch_size,\n",
        "                block_size=block_size,\n",
        "                head_size=head_size,\n",
        "                dropout=dropout,\n",
        "            )\n",
        "            head.build(((None, None, embedding_dim), (None, None, embedding_dim), (None, None, embedding_dim)))\n",
        "            self.heads.append(head)\n",
        "        \n",
        "        # this linear layer is used to 'merge' the multiple heads acquired knowledge\n",
        "        self.proj = Dense(units=embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        self.dropout = Dropout(dropout)\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        # concatenate the heads outputs in the C dimension\n",
        "        out =  tf.concat([h(inp) for h in self.heads], axis=-1)\n",
        "        # apply thE projection and dropout\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        super(MultiHeadAttention, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VGMjfU_IqQdo"
      },
      "outputs": [],
      "source": [
        "#Simple feed forward for data computation\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, embedding_dim, dropout, resize_to_input_dim=True, spread_dim=None):\n",
        "        # resize_to_input_dim -> Should be False only to last block element when posterior computation is gonna happen so it doesn't need to output embedding_dim sized elements to another block\n",
        "        # spread_dim -> the heads output comes concatenated in sequence so is computed and joint by the spread layer layer\n",
        "        super().__init__()\n",
        "        last_layer = [\n",
        "            Dense(embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer()), \n",
        "            Dropout(dropout)\n",
        "        ] if resize_to_input_dim else []\n",
        "        \n",
        "        self.net = Sequential([\n",
        "            Dense(spread_dim if spread_dim is not None else 4 * embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer()),\n",
        "            Dropout(dropout),\n",
        "            *last_layer\n",
        "        ])\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "YnyFKuPEqQdp"
      },
      "outputs": [],
      "source": [
        "# Block containing a multi head attention module and a feed forward linear computation\n",
        "class Block(Layer):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "    def __init__(self, batch_size, block_size, emb_dim, num_heads, dropout, resize_to_input_dim=None, spread_dim=None):\n",
        "        super().__init__()\n",
        "        self.resize_to_input_dim = resize_to_input_dim\n",
        "        head_size = emb_dim // num_heads # each head gets a portion of the embeddings so different relations can be learned\n",
        "        \n",
        "        self.sa = MultiHeadAttention(batch_size, block_size, emb_dim, num_heads, head_size, dropout)\n",
        "        self.st_ln = LayerNormalization()\n",
        "        self.gp_ln = LayerNormalization()\n",
        "        self.ac_ln = LayerNormalization()\n",
        "\n",
        "        self.ffwd = FeedForward(emb_dim, dropout, resize_to_input_dim, spread_dim)\n",
        "        self.ffwd_ln = LayerNormalization()\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        st_emp, global_pos_emb, act_emb = inp[0], inp[1], inp[2]\n",
        "\n",
        "        # Multi head attention with layer norm\n",
        "        x = st_emp + self.sa([\n",
        "            self.st_ln(st_emp), \n",
        "            self.gp_ln(global_pos_emb + st_emp), \n",
        "            self.ac_ln(act_emb),\n",
        "        ])\n",
        "        \n",
        "        # feed forward with layer norm\n",
        "        ffw = self.ffwd(self.ffwd_ln(x))\n",
        "        x = (x + ffw) if self.resize_to_input_dim else ffw\n",
        "\n",
        "        return x\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        st_emb, global_pos_emb, act_emb = input_shape\n",
        "        self.st_ln.build(st_emb)\n",
        "        self.gp_ln.build(global_pos_emb)\n",
        "        self.ac_ln.build(act_emb)\n",
        "        self.ffwd_ln.build(st_emb)\n",
        "        super(Block, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_value = lambda : RandomNormal(mean=0.0, stddev=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "V4uZbSagqQdq"
      },
      "outputs": [],
      "source": [
        "class GPTModel(Model):\n",
        "    def __init__(self, n_layer, batch_size, block_size, embedding_dim, out_dim, num_heads, dropout, ffw):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.state_embedding = Dense(units=embedding_dim, kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        self.action_embedding = Dense(units=embedding_dim, kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        \n",
        "        self.blocks = []\n",
        "        for i in range(n_layer):\n",
        "            block = Block(batch_size, block_size, embedding_dim, num_heads, dropout,\n",
        "                resize_to_input_dim = (i != n_layer - 1 ),  \n",
        "                spread_dim = out_dim if (i == n_layer - 1 ) else None,\n",
        "            )\n",
        "            block.build(((None, None, embedding_dim), (None, None, embedding_dim), (None, None, embedding_dim)))\n",
        "            self.blocks.append(block)\n",
        "\n",
        "        self.ffw = ffw\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def get_local_position_sin_encoding(self, batch_size, block_size, n=10000):\n",
        "        positions = np.tile([np.arange(block_size)], [batch_size, 1])\n",
        "        batch_size, block_size = positions.shape[:2]\n",
        "        aux = np.tile(np.tile([np.arange(self.embedding_dim)], [block_size, 1]), [batch_size, 1, 1])\n",
        "        denominator = tf.cast(n**((2*(aux//2))/self.embedding_dim), dtype=tf.float32)\n",
        "        val = tf.cast(np.tile(positions, [1, 1, self.embedding_dim]), dtype=tf.float32)\n",
        "        P = (np.sin(val/denominator) * ((aux + 1)%2)) + (np.cos(val/denominator)*(aux%2))\n",
        "        return P\n",
        "  \n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        states, global_positions, actions = inp[0], inp[1], inp[2]\n",
        "        B, T, C = states.shape\n",
        "        if(T is None): T = self.block_size\n",
        "        if(B is None): B = self.batch_size\n",
        "\n",
        "        #local_position = self.get_local_position_sin_encoding(batch_size=B, block_size=T)\n",
        "        act_emb = self.action_embedding(actions)\n",
        "        st_emb = self.state_embedding(states)\n",
        "        \n",
        "        for block in self.blocks: st_emb = block((st_emb, global_positions, act_emb))\n",
        "        logits = self.ffw(st_emb)\n",
        "\n",
        "        return logits\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def generate(self, states, positions, actions):\n",
        "        # crop idx to the last block_size tokens\n",
        "        st_cond = states[:, -self.block_size:, :]\n",
        "        pos_cond = positions[:, -self.block_size:, :]\n",
        "        act_cond = actions[:, -self.block_size:, :]\n",
        "        # get the predictions\n",
        "        actions = self([st_cond, pos_cond, act_cond])\n",
        "        # focus only on the last time step\n",
        "        return actions\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        states, positions, actions = input_shape\n",
        "        self.action_embedding.build(actions)\n",
        "        self.state_embedding.build(states)\n",
        "        super(GPTModel, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdauE0A-qQdr",
        "outputId": "f775f548-57dc-43a6-877b-8cf35079d9a6"
      },
      "outputs": [],
      "source": [
        "class Actor(object):\n",
        "    def __init__(self, n_layer, batch_size, block_size, state_dim, action_dim, embedding_dim, num_heads, dropout, action_range, lr, tau):\n",
        "        #Network dimensions\n",
        "        self.inp_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        ffw = lambda: Sequential([\n",
        "            Dense(16, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Dropout(dropout),\n",
        "            BatchNormalization(),\n",
        "            Dense(action_dim, activation='tanh', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Lambda(lambda i: i * action_range, dtype='float64'),\n",
        "        ]) \n",
        "\n",
        "        #Parameter that coordinates the soft updates on the target weights\n",
        "        self.tau = tau\n",
        "\n",
        "        #Generates the optimization function - used in the agent to generate gradients\n",
        "        self.optimizer = Adam(lr)\n",
        "\n",
        "        #Generates the actor model\n",
        "        self.model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=512,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.model.build(((None, None, state_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Generates the actor target model\n",
        "        self.target_model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=512,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.target_model.build(((None, None, state_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Set the weights to be the same in the begining\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def predict(self, states, positions, actions):\n",
        "        return self.model.generate(states, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def target_predict(self, states, positions, actions):\n",
        "        return self.target_model.generate(states, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def act(self, states, positions, actions):\n",
        "        action = self.predict(states, positions, actions)\n",
        "        # Gets the last action only\n",
        "        action = action[0, -1, :]\n",
        "        return action\n",
        "\n",
        "    #--------------------------------------------------------------------\n",
        "    def transferWeights(self):\n",
        "        weights = self.model.get_weights()\n",
        "        target_weights = self.target_model.get_weights()\n",
        "        new_weights = []\n",
        "        \n",
        "        for i in range(len(weights)):\n",
        "            new_weights.append((self.tau * weights[i]) + ((1.0 - self.tau) * target_weights[i]))\n",
        "        \n",
        "        self.target_model.set_weights(new_weights)\n",
        "        \n",
        "    #--------------------------------------------------------------------\n",
        "    def saveModel(self, path):\n",
        "        self.model.save(path + '_actor_model.h5')\n",
        "        self.target_model.save(path + '_actor_target_model.h5')\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def loadModel(self, path):\n",
        "        self.target_model = load_model(path)\n",
        "        self.model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iws_SlRZqQds",
        "outputId": "30dfbb02-a02f-4373-fb58-8fd4db3b5774"
      },
      "outputs": [],
      "source": [
        "class Critic(object):\n",
        "    def __init__(self, n_layer, batch_size, block_size, state_dim, action_dim, embedding_dim, out_dim, num_heads, dropout, lr, tau):\n",
        "        #Network dimensions\n",
        "        self.inp_dim = state_dim + action_dim\n",
        "        ffw = lambda: Sequential([\n",
        "                Dense(8, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "                Dropout(dropout),\n",
        "                BatchNormalization(),\n",
        "                Dense(out_dim, activation='linear', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            ]) \n",
        "\n",
        "        #Parameter that coordinates the soft updates on the target weights\n",
        "        self.tau = tau\n",
        "\n",
        "        #Generates the optimization function - used in the agent to generate gradients\n",
        "        self.optimizer = Adam(lr)\n",
        "\n",
        "        #Generates the actor model\n",
        "        self.model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.model.build(((None, None, self.inp_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Generates the actor target model\n",
        "        self.target_model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.target_model.build(((None, None, self.inp_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Set the weights to be the same in the begining\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def predict(self, states, next_actions, positions, actions):\n",
        "        states = tf.cast(states, tf.float32) \n",
        "        next_actions = tf.cast(next_actions, tf.float32) \n",
        "        positions = tf.cast(positions, tf.float32)\n",
        "        actions = tf.cast(actions, tf.float32)\n",
        "        inp = tf.concat([states, next_actions], 2)\n",
        "        return self.model.generate(inp, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def target_predict(self, states, next_actions, positions, actions):\n",
        "        states = tf.cast(states, tf.float32) \n",
        "        next_actions = tf.cast(next_actions, tf.float32) \n",
        "        positions = tf.cast(positions, tf.float32)\n",
        "        actions = tf.cast(actions, tf.float32)\n",
        "        inp = tf.concat([states, next_actions], 2)\n",
        "        return self.target_model.generate(inp, positions, actions)\n",
        "    \n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def transferWeights(self):\n",
        "        weights = self.model.get_weights()\n",
        "        target_weights = self.target_model.get_weights()\n",
        "        new_weights = []\n",
        "        \n",
        "        for i in range(len(weights)):\n",
        "            new_weights.append((self.tau * weights[i]) + ((1.0 - self.tau) * target_weights[i]))\n",
        "        \n",
        "        self.target_model.set_weights(new_weights)\n",
        "        \n",
        "    #--------------------------------------------------------------------\n",
        "    def saveModel(self, path):\n",
        "        self.model.save(path + '_critic_model.h5')\n",
        "        self.target_model.save(path + '_critic_target_model.h5')\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def loadModel(self, path):\n",
        "        self.target_model = load_model(path)\n",
        "        self.model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "n2y8GZ7tqQds"
      },
      "outputs": [],
      "source": [
        "class DDPG_GPT_Agent(object):\n",
        "    def __init__(self, a_n_layers, c_n_layers, batch_size, block_size, state_dim, action_dim, a_n_heads, c_n_heads, \n",
        "        dropout, action_min, action_max, memory_size, gamma, a_lr, c_lr, tau, epsilon, epsilon_decay, \n",
        "        epsilon_min, a_embedding_dim, c_embedding_dim):\n",
        "        \n",
        "        self.block_size = block_size\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.action_min = action_min\n",
        "        self.action_max = action_max\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.a_embedding_dim = a_embedding_dim\n",
        "        self.c_embedding_dim = c_embedding_dim\n",
        "\n",
        "        self.episode_batch_size = batch_size\n",
        "        self.steps_batch_size = 1\n",
        "\n",
        "        #Creates the Replay Buffer\n",
        "        self.memory = ReplayBuffer(memory_size, self.episode_batch_size)\n",
        "\n",
        "        #Creates the noise generator\n",
        "        self.ou_noise = OUActionNoise(mean=np.zeros(action_dim))\n",
        "\n",
        "        #Creates the actor\n",
        "        self.actor = Actor(\n",
        "            n_layer=a_n_layers,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            state_dim=state_dim, \n",
        "            action_dim=action_dim, \n",
        "            embedding_dim=a_embedding_dim,\n",
        "            num_heads=a_n_heads, \n",
        "            dropout=dropout, \n",
        "            action_range=action_max, \n",
        "            lr=a_lr, \n",
        "            tau=tau,\n",
        "        )\n",
        "        \n",
        "        #Creates the critic\n",
        "        self.critic = Critic(\n",
        "            n_layer=c_n_layers,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            state_dim=state_dim, \n",
        "            action_dim=action_dim, \n",
        "            embedding_dim=c_embedding_dim,\n",
        "            out_dim=1,\n",
        "            num_heads=c_n_heads, \n",
        "            dropout=dropout, \n",
        "            lr=c_lr, \n",
        "            tau=tau,\n",
        "        )\n",
        "    \n",
        "    #--------------------------------------------------------------------     \n",
        "    def act(self, env):\n",
        "        action = np.zeros(self.action_dim)\n",
        "        state = env.reset()\n",
        "        step = np.array([1])\n",
        "\n",
        "        actions = action.reshape(1, 1, -1)\n",
        "        states = state.reshape(1, 1, -1)\n",
        "        positions = step.reshape(1, 1, -1)\n",
        "\n",
        "        done = False\n",
        "        while not done:\n",
        "            env.render()\n",
        "            action = self.policy(states, positions, actions, explore=False)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            step += 1\n",
        "\n",
        "            states = tf.concat((states, state.reshape(1, 1, -1)), axis=1)\n",
        "            positions = tf.concat((positions, np.array([step]).reshape(1, 1, -1)), axis=1)\n",
        "            actions = tf.concat((actions, action.reshape(1, 1, -1)), axis=1)\n",
        "        \n",
        "        return\n",
        "    \n",
        "    #-------------------------------------------------------------------- \n",
        "    def get_position_sin_encoding(self, embedding_dim, positions, n=10000):\n",
        "        batch_size, block_size = positions.shape[:2]\n",
        "        aux = np.tile(np.tile([np.arange(embedding_dim)], [block_size, 1]), [batch_size, 1, 1])\n",
        "        denominator = tf.cast(n**((2*(aux//2))/embedding_dim), dtype=tf.float32)\n",
        "        val = tf.cast(np.tile(positions, [1, 1, embedding_dim]), dtype=tf.float32)\n",
        "        P = (np.sin(val/denominator) * ((aux + 1)%2)) + (np.cos(val/denominator)*(aux%2))\n",
        "        return P\n",
        "\n",
        "    #-------------------------------------------------------------------- \n",
        "    def policy(self, states, positions, actions, explore=True):\n",
        "        \"\"\" Generates an action from a group of states and add exploration \"\"\"\n",
        "        # gets the action\n",
        "        action = self.actor.act(states, self.get_position_sin_encoding(self.a_embedding_dim, positions), actions)\n",
        "        # takes the exploration with the epsilon probability\n",
        "        if explore and np.random.rand() < self.epsilon: action += self.ou_noise()\n",
        "        # clip the action to be between min and max values\n",
        "        action = np.clip(action, a_min=self.action_min, a_max=self.action_max)\n",
        "        action[np.isnan(action)] = 0\n",
        "\n",
        "        return action   \n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def record_memories(self, steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        self.memory.append(steps)\n",
        "        return\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def learn(self, memory_steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        \"\"\" Append an experience to the memory and replay memory if possible \"\"\"\n",
        "        self.record_memories(memory_steps)\n",
        "        if self.memory.hasMinLength: self.replay_memory()\n",
        "        return\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def episode_to_batch(self, episode):\n",
        "        #episode = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        if len(episode) > (self.block_size + self.steps_batch_size):\n",
        "            steps_idxs = np.random.choice(np.arange(self.block_size, len(episode)), size=self.steps_batch_size-1, replace=False)\n",
        "            steps_idxs = np.append(steps_idxs, len(episode))\n",
        "        else: steps_idxs = np.arange(self.block_size, len(episode))\n",
        "        \n",
        "        batch = np.array([episode[i-self.block_size:i] for i in steps_idxs])\n",
        "        #batch = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        return batch\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def null_step(self, step):\n",
        "        #step = {'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}\n",
        "        step['reward'] = 0\n",
        "        step['done'] = True\n",
        "        return step\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def episode_pad(self, episode):\n",
        "        #episode = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        return np.concatenate((episode, [self.null_step(episode[-1]) for _ in range(self.block_size - len(episode) + 1)]))\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def get_episodes_batches(self, episodes):\n",
        "        #episodes = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        batch = None\n",
        "\n",
        "        join_episode = lambda final_value, aux_value: aux_value if final_value is None else np.concatenate((final_value, aux_value))\n",
        "\n",
        "        for episode in episodes:\n",
        "            if len(episode) <= self.block_size: episode = self.episode_pad(episode)\n",
        "            ep_batch = self.episode_to_batch(episode)\n",
        "            batch = join_episode(batch, ep_batch)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    #--------------------------------------------------------------------    \n",
        "    def replay_memory(self):\n",
        "        \"\"\" Replay a batch of memories \"\"\"\n",
        "\n",
        "        # Get sample block from the replay buffer\n",
        "        episodes = self.memory.getEpisodes()\n",
        "        batch = self.get_episodes_batches(episodes)\n",
        "        #batch = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        to_tensor = lambda value: tf.convert_to_tensor(value, dtype='float32')\n",
        "        get_batch_element = lambda key, batch: to_tensor([[step[key] for step in block] for block in batch])\n",
        "        \n",
        "        positions = tf.expand_dims(get_batch_element('step', batch), axis=-1)\n",
        "        next_positions_actor = self.get_position_sin_encoding(self.a_embedding_dim, positions + 1)\n",
        "        next_positions_critic = self.get_position_sin_encoding(self.c_embedding_dim, positions + 1)\n",
        "        positions_actor = self.get_position_sin_encoding(self.a_embedding_dim, positions)\n",
        "        positions_critic = self.get_position_sin_encoding(self.c_embedding_dim, positions)\n",
        "\n",
        "        states = get_batch_element('state', batch)\n",
        "        next_states = get_batch_element('next_state', batch)\n",
        "\n",
        "        prev_actions = get_batch_element('prev_action', batch)  \n",
        "        actions = get_batch_element('action', batch)\n",
        "\n",
        "        rewards = tf.expand_dims(get_batch_element('reward', batch), axis=-1)\n",
        "        done = tf.expand_dims(get_batch_element('done', batch), axis=-1)\n",
        "\n",
        "        #Train the critic\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Compute the actor target actions\n",
        "            target_actions = self.actor.target_predict(next_states, next_positions_actor, actions)\n",
        "            # Compute the critic target values \n",
        "            predicted_return = self.critic.target_predict(next_states, target_actions, next_positions_critic, actions)\n",
        "            # The return for the last block element\n",
        "            last_return = predicted_return[:, -1, :]\n",
        "\n",
        "            # Compute the gamma tensor based on the block step\n",
        "            gamma_values = lambda i: tf.expand_dims(tf.repeat([[self.gamma**(k - i+1) for k in range(i, rewards.shape[1]-1)]], repeats=rewards.shape[0], axis=0), axis=-1)\n",
        "            # Compute the gamma weighted reward for a given block step\n",
        "            weighted_next_rewards = lambda i: tf.math.reduce_sum(rewards[:, i+1:, :] * gamma_values(i), axis=1)\n",
        "            # The gamma weight for the last return bootstrap\n",
        "            last_return_weight = lambda i: self.gamma ** (rewards.shape[1] - i)\n",
        "            # Compute the done value for a block step\n",
        "            state_done = lambda i: 1 - done[:, i, :]\n",
        "            \n",
        "            # Compute the return target values\n",
        "            computed_returns = tf.stack([\n",
        "                *[((weighted_next_rewards(i) + (last_return_weight(i) * last_return * state_done(-1))) * state_done(i)) for i in range(rewards.shape[1]-1)], \n",
        "                tf.zeros([rewards.shape[0], 1]),\n",
        "            ], axis=1)\n",
        "            #bootstrapped_returns = self.gamma * predicted_return * (1 - done)\n",
        "            \n",
        "            y = rewards + computed_returns\n",
        "            # Predict the expected reward associated with taking the target predicted action in the state\n",
        "            critic_value = self.critic.predict(states, actions, positions_critic, prev_actions)\n",
        "            # Compute the critic loss  \n",
        "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
        "            \n",
        "        critic_grad = tape.gradient(critic_loss, self.critic.model.trainable_variables)\n",
        "        self.critic.optimizer.apply_gradients(\n",
        "            (grad, var) \n",
        "            for (grad, var) in zip(critic_grad, self.critic.model.trainable_variables) \n",
        "            if grad is not None\n",
        "        )\n",
        "        \n",
        "        #Train the actor\n",
        "        with tf.GradientTape() as tape:\n",
        "            acts = self.actor.predict(states, positions_actor, prev_actions)\n",
        "            critic_grads = self.critic.predict(states, acts, positions_critic, prev_actions)\n",
        "            #Used -mean as we want to maximize the value given by the critic for our actions\n",
        "            actor_loss = -tf.math.reduce_mean(critic_grads)\n",
        "\n",
        "        actor_grad = tape.gradient(actor_loss, self.actor.model.trainable_variables)\n",
        "        self.actor.optimizer.apply_gradients(\n",
        "            (grad, var) \n",
        "            for (grad, var) in zip(actor_grad, self.actor.model.trainable_variables)\n",
        "            if grad is not None\n",
        "        )\n",
        "            \n",
        "        #Update the model weights\n",
        "        self.actor.transferWeights()\n",
        "        self.critic.transferWeights() \n",
        "        \n",
        "    #--------------------------------------------------\n",
        "    def print_data(self, verbose, episode, step, score):\n",
        "        if verbose:\n",
        "            print(\"\\r                                                                                                     \", end=\"\")\n",
        "            print(\"\\rEpisode: \"+str(episode+1)+\"\\t Step: \"+str(step)+\"\\tReward: \"+str(round(score, 2)) ,end=\"\")\n",
        "        return\n",
        "\n",
        "    #--------------------------------------------------------------------     \n",
        "    def train(self, env, num_episodes, step_per_train, verbose, verbose_num, end_on_complete=False, complete_num=1, complete_value=float('inf'), act_after_batch=False):\n",
        "        scores_history = []\n",
        "        steps_history = []\n",
        "        complete = 0\n",
        "        print(\"BEGIN\\n\")\n",
        "        \n",
        "        for episode in range(num_episodes):\n",
        "            done = False\n",
        "            score, step = 0, 1\n",
        "            state = env.reset()\n",
        "            prev_action = np.zeros(self.action_dim)\n",
        "\n",
        "            states = state.reshape(1, 1, -1)\n",
        "            positions = np.array([step]).reshape(1, 1, -1)\n",
        "            actions = prev_action.reshape(1, 1, -1)\n",
        "            \n",
        "            while not done:\n",
        "                memory_steps = []\n",
        "\n",
        "                for _ in range(step_per_train):\n",
        "                    action = self.policy(states, positions, actions)\n",
        "                    new_state, reward, done, _ = env.step(action)\n",
        "                    self.print_data(verbose, episode, step, score)\n",
        "                    \n",
        "                    memory_steps.append({\n",
        "                        'step': step, \n",
        "                        'prev_action': prev_action, \n",
        "                        'state': state, \n",
        "                        'action':  action, \n",
        "                        'next_state': new_state, \n",
        "                        'reward': reward, \n",
        "                        'done':  int(done),\n",
        "                    })\n",
        "\n",
        "                    state = new_state\n",
        "                    prev_action = action\n",
        "                    step += 1\n",
        "                    score += reward\n",
        "\n",
        "                    states = tf.concat((states, new_state.reshape(1, 1, -1)), axis=1)\n",
        "                    positions = tf.concat((positions, np.array([step]).reshape(1, 1, -1)), axis=1)\n",
        "                    actions = tf.concat((actions, action.reshape(1, 1, -1)), axis=1)\n",
        "                    if done: break\n",
        "                \n",
        "                if len(memory_steps) > 0: self.learn(memory_steps)\n",
        "                self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)\n",
        "\n",
        "            scores_history.append(score)\n",
        "            steps_history.append(step)\n",
        "            \n",
        "            #If the score is bigger or equal than the complete score it add one to the completed number\n",
        "            if(score >= complete_value):\n",
        "                complete += 1\n",
        "                #If the flag is true the agent ends the trainig on the firs complete episode\n",
        "                if end_on_complete and complete >= complete_num: break\n",
        "            \n",
        "            #These information are printed after each verbose_num episodes\n",
        "            if((episode+1)%verbose_num == 0):\n",
        "                print(\"\\r                                                                                                          \", end=\"\")\n",
        "                print(\"\\rEpisodes: \", episode+1, \"/\", num_episodes, \n",
        "                      \"\\n\\tTotal reward: \", round(np.mean(scores_history[-verbose_num:]), 2), '+/-', round(np.std(scores_history[-verbose_num:]), 2), \n",
        "                      \"\\n\\tNum. steps: \", round(np.mean(steps_history[-verbose_num:]), 2), '+/-', round(np.std(steps_history[-verbose_num:]), 2), \n",
        "                      *[\"\\n\\tCompleted: \", complete] if complete_value != float('inf') else '', \n",
        "                      \"\\n--------------------------\",\n",
        "                    )\n",
        "                \n",
        "                #If the flag is true the agent act and render the episode after each verbose_num episodes\n",
        "                if act_after_batch: self.act(env)\n",
        "                \n",
        "                #Set the number of completed episodes on the batch to zero\n",
        "                complete = 0\n",
        "\n",
        "        print(\"\\nFINISHED\")\n",
        "        \n",
        "        return scores_history, steps_history\n",
        "    #--------------------------------------------------------------------     \n",
        "    def save(self, path):\n",
        "        self.actor.saveModel(path)\n",
        "        self.critic.saveModel(path)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def load(self, a_path, c_path):\n",
        "        self.actor.loadModel(a_path)\n",
        "        self.critic.loadModel(c_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wS8tg8OqQdt",
        "outputId": "3d5e1dc5-3b35-4c65-b236-f11b903b86d7",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", continuous=True, max_episode_steps=1000)\n",
        "batch_size = 128\n",
        "block_size = 32\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "action_min = env.action_space.low\n",
        "action_max = env.action_space.high\n",
        "dropout = 0.1\n",
        "memory_size = 100\n",
        "gamma = 0.99\n",
        "\n",
        "epsilon = 1\n",
        "epsilon_decay = 0.9991\n",
        "epsilon_min = 0.2\n",
        "\n",
        "tau = 5e-4\n",
        "\n",
        "# Actor hyperparameter\n",
        "a_n_layer = 2\n",
        "a_num_heads = 1\n",
        "a_embedding_dim = 6\n",
        "a_learning_rate = 4e-4\n",
        "\n",
        "# Critic hyperparameter\n",
        "c_n_layer = 1\n",
        "c_num_heads = 2\n",
        "c_embedding_dim = 12\n",
        "c_learning_rate = 8e-4\n",
        "\n",
        "agent = DDPG_GPT_Agent(\n",
        "    a_n_layers = a_n_layer,\n",
        "    c_n_layers = c_n_layer, \n",
        "    batch_size = batch_size, \n",
        "    block_size=block_size, \n",
        "    state_dim=state_dim, \n",
        "    action_dim=action_dim, \n",
        "    a_embedding_dim=a_embedding_dim,\n",
        "    c_embedding_dim=c_embedding_dim,\n",
        "    a_n_heads=a_num_heads, \n",
        "    c_n_heads=c_num_heads,\n",
        "    dropout=dropout, \n",
        "    action_min=action_min, \n",
        "    action_max=action_max, \n",
        "    memory_size=memory_size, \n",
        "    gamma=gamma, \n",
        "    a_lr=a_learning_rate, \n",
        "    c_lr=c_learning_rate, \n",
        "    tau=tau, \n",
        "    epsilon=epsilon, \n",
        "    epsilon_decay=epsilon_decay, \n",
        "    epsilon_min=epsilon_min,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aCvb6NiqQdu",
        "outputId": "bb989c21-13bb-441f-bc9a-179631844892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEGIN\n",
            "\n",
            "Episodes:  10 / 1000                                                                                      \n",
            "\tTotal reward:  -380.48 +/- 201.73 \n",
            "\tNum. steps:  95.8 +/- 33.68 \n",
            "--------------------------\n",
            "Episodes:  20 / 1000                                                                                      \n",
            "\tTotal reward:  -541.54 +/- 205.54 \n",
            "\tNum. steps:  67.9 +/- 10.9 \n",
            "--------------------------\n",
            "Episodes:  30 / 1000                                                                                      \n",
            "\tTotal reward:  -156.72 +/- 73.42 \n",
            "\tNum. steps:  69.9 +/- 11.91 \n",
            "--------------------------\n",
            "Episodes:  40 / 1000                                                                                      \n",
            "\tTotal reward:  -137.69 +/- 38.66 \n",
            "\tNum. steps:  78.0 +/- 16.79 \n",
            "--------------------------\n",
            "Episodes:  50 / 1000                                                                                      \n",
            "\tTotal reward:  -145.41 +/- 46.31 \n",
            "\tNum. steps:  69.9 +/- 12.05 \n",
            "--------------------------\n",
            "Episodes:  60 / 1000                                                                                      \n",
            "\tTotal reward:  -116.13 +/- 39.27 \n",
            "\tNum. steps:  71.7 +/- 10.1 \n",
            "--------------------------\n",
            "Episodes:  70 / 1000                                                                                      \n",
            "\tTotal reward:  -118.58 +/- 11.13 \n",
            "\tNum. steps:  69.0 +/- 8.32 \n",
            "--------------------------\n",
            "Episodes:  80 / 1000                                                                                      \n",
            "\tTotal reward:  -121.99 +/- 13.96 \n",
            "\tNum. steps:  69.9 +/- 10.6 \n",
            "--------------------------\n",
            "Episodes:  90 / 1000                                                                                      \n",
            "\tTotal reward:  -120.02 +/- 10.85 \n",
            "\tNum. steps:  74.2 +/- 15.0 \n",
            "--------------------------\n",
            "Episodes:  100 / 1000                                                                                     \n",
            "\tTotal reward:  -120.55 +/- 8.8 \n",
            "\tNum. steps:  77.2 +/- 11.56 \n",
            "--------------------------\n",
            "Episodes:  110 / 1000                                                                                     \n",
            "\tTotal reward:  -124.24 +/- 23.61 \n",
            "\tNum. steps:  74.4 +/- 16.79 \n",
            "--------------------------\n",
            "Episodes:  120 / 1000                                                                                     \n",
            "\tTotal reward:  -115.98 +/- 9.05 \n",
            "\tNum. steps:  72.8 +/- 11.65 \n",
            "--------------------------\n",
            "Episodes:  130 / 1000                                                                                     \n",
            "\tTotal reward:  -229.59 +/- 100.5 \n",
            "\tNum. steps:  106.5 +/- 25.89 \n",
            "--------------------------\n",
            "Episodes:  140 / 1000                                                                                     \n",
            "\tTotal reward:  -481.66 +/- 237.9 \n",
            "\tNum. steps:  105.4 +/- 26.36 \n",
            "--------------------------\n",
            "Episodes:  150 / 1000                                                                                     \n",
            "\tTotal reward:  -195.54 +/- 132.15 \n",
            "\tNum. steps:  103.4 +/- 34.99 \n",
            "--------------------------\n",
            "Episodes:  160 / 1000                                                                                     \n",
            "\tTotal reward:  -169.75 +/- 63.82 \n",
            "\tNum. steps:  106.3 +/- 25.42 \n",
            "--------------------------\n",
            "Episodes:  170 / 1000                                                                                     \n",
            "\tTotal reward:  -174.95 +/- 70.68 \n",
            "\tNum. steps:  94.2 +/- 21.65 \n",
            "--------------------------\n",
            "Episodes:  180 / 1000                                                                                     \n",
            "\tTotal reward:  -231.4 +/- 87.3 \n",
            "\tNum. steps:  112.4 +/- 21.85 \n",
            "--------------------------\n",
            "Episode: 185\t Step: 26\tReward: -71.58                                                                "
          ]
        }
      ],
      "source": [
        "num_episodes = 1000\n",
        "step_per_train = 2\n",
        "verbose = True\n",
        "verbose_num = 10\n",
        "act_after_batch = True\n",
        "\n",
        "scores, steps = agent.train(\n",
        "    env=env, \n",
        "    num_episodes=num_episodes,\n",
        "    step_per_train=step_per_train,\n",
        "    verbose=verbose, \n",
        "    verbose_num=verbose_num,  \n",
        "    act_after_batch=act_after_batch,\n",
        ")\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb5a7fdbe80>]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(scores)), scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb5cc1fa1a0>]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(steps)), steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", continuous=True)\n",
        "agent.act(env)\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
