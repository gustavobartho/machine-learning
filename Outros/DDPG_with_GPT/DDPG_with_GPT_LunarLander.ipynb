{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8WT_0Y-KqQdW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-29 11:00:07.392648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/user/JUPYTER_LAB/My_Projects/Outros/DDPG_with_GPT/DDPG_with_GPT_LunarLander.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/JUPYTER_LAB/My_Projects/Outros/DDPG_with_GPT/DDPG_with_GPT_LunarLander.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/JUPYTER_LAB/My_Projects/Outros/DDPG_with_GPT/DDPG_with_GPT_LunarLander.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer, Dense, Dropout, BatchNormalization, LayerNormalization, Lambda\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user/JUPYTER_LAB/My_Projects/Outros/DDPG_with_GPT/DDPG_with_GPT_LunarLander.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomNormal, Zeros\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreading\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m---> 26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m function_pb2\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:157\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m random\n\u001b[1;32m    156\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ctypeslib\n\u001b[0;32m--> 157\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ma\n\u001b[1;32m    158\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m matrixlib \u001b[39mas\u001b[39;00m _mat\n\u001b[1;32m    159\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmatrixlib\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/__init__.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m=============\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mMasked Arrays\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m extras\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/core.py:1194\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[39mreturn\u001b[39;00m masked_result\n\u001b[1;32m   1193\u001b[0m \u001b[39m# Unary ufuncs\u001b[39;00m\n\u001b[0;32m-> 1194\u001b[0m exp \u001b[39m=\u001b[39m _MaskedUnaryOperation(umath\u001b[39m.\u001b[39;49mexp)\n\u001b[1;32m   1195\u001b[0m conjugate \u001b[39m=\u001b[39m _MaskedUnaryOperation(umath\u001b[39m.\u001b[39mconjugate)\n\u001b[1;32m   1196\u001b[0m sin \u001b[39m=\u001b[39m _MaskedUnaryOperation(umath\u001b[39m.\u001b[39msin)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/ma/core.py:915\u001b[0m, in \u001b[0;36m_MaskedUnaryOperation.__init__\u001b[0;34m(self, mufunc, fill, domain)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, mufunc, fill\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, domain\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 915\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(mufunc)\n\u001b[1;32m    916\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill \u001b[39m=\u001b[39m fill\n\u001b[1;32m    917\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdomain \u001b[39m=\u001b[39m domain\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout, BatchNormalization, LayerNormalization, Lambda\n",
        "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-28 18:42:55.925076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/opt/cuda/lib64\n",
            "2023-05-28 18:42:55.925511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/opt/cuda/lib64\n",
            "2023-05-28 18:42:55.925870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/opt/cuda/lib64\n",
            "2023-05-28 18:43:04.990336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/home/user/.local/lib/python3.10/site-packages/nvidia/cuda_runtime/lib:/opt/cuda/lib64\n",
            "2023-05-28 18:43:05.020782: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vQX1S3qQdc"
      },
      "source": [
        "# Objective: Create a DDPG algorithm with a GPT as the Actor network.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeO6YvRbqQdf",
        "outputId": "98286af3-47a0-4c4a-8c82-c041308ccc0c"
      },
      "outputs": [],
      "source": [
        "#Ornstein-Uhlenbeck Noise \n",
        "class OUActionNoise(object):\n",
        "    def __init__(self, mean, sigma=0.7, theta=0.3, dt=0.4, x0=None):\n",
        "        self.mean = mean\n",
        "        self.sigma = sigma\n",
        "        self.theta = theta\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.reset()\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "    #Method that enables to write classes where the instances behave like functions and can be called like a function.    \n",
        "    def __call__(self):\n",
        "        x = self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
        "        self.x_prev = x\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "    def reset(self):\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mean)\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-n5JPCPqQdi",
        "outputId": "a2773b70-2744-4aa3-c777-6acd96c63981"
      },
      "outputs": [],
      "source": [
        "#Replay Buffer \n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size, batch_size):\n",
        "        '''\n",
        "        Args:\n",
        "            size (integer): The size of the replay buffer.              \n",
        "            batch_size (integer): The batch size.\n",
        "            block_size (integer): \n",
        "        '''\n",
        "        self.buffer = [[]]\n",
        "        self.batch_size = batch_size\n",
        "        self.max_size = size\n",
        "        \n",
        "    #--------------------------------------------------    \n",
        "    def append(self, steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        if self.size >= self.max_size: del self.buffer[0]\n",
        "        for step in steps: self.buffer[-1].append(step)\n",
        "        # if done create new episode entry\n",
        "        # (state, action, reward, done)\n",
        "        if (steps[-1]['done']): self.buffer.append([])\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def clear(self):\n",
        "        self.buffer.clear()\n",
        "    \n",
        "    #--------------------------------------------------    \n",
        "    def getEpisodes(self):\n",
        "        episodes = np.random.choice(\n",
        "            np.arange(self.size - 1), #don't chose the current step\n",
        "            size=(self.batch_size,), \n",
        "            replace=True\n",
        "        )\n",
        "        return  [self.buffer[episode] for episode in episodes]\n",
        "    \n",
        "    #--------------------------------------------------  \n",
        "    @property  \n",
        "    def size(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            Number of elements in the buffer\n",
        "        '''\n",
        "        return len(self.buffer)\n",
        "\n",
        "    #--------------------------------------------------  \n",
        "    @property \n",
        "    def hasMinLength(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            Boolean indicating if the memory have the minimum number of elements or not\n",
        "        '''\n",
        "        return (self.size > 8)\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    @property  \n",
        "    def data(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            List with all the elements in the buffer\n",
        "        '''\n",
        "        return self.buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1en0TDn5qQdl",
        "outputId": "c485ce90-2d8c-4f0a-cc48-6efad0b8233c"
      },
      "outputs": [],
      "source": [
        "gpt_kernel_initializer = lambda: RandomNormal(mean=0.0, stddev=0.1)\n",
        "gpt_bias_initializer = lambda: Zeros()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxHdLrUWqQdm"
      },
      "outputs": [],
      "source": [
        "# Individual Head of self-attention\n",
        "class Head(Layer):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, batch_size, block_size, head_size, dropout):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.block_size = block_size\n",
        "\n",
        "        # key, query and value layers\n",
        "        self.key = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "        self.query = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "        self.value = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout_v = Dropout(dropout)\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        state_emb, global_pos_emb, action_emb = inp[0], inp[1], inp[2]\n",
        "        B, T, C = state_emb.shape\n",
        "        if(B is None): B = self.batch_size \n",
        "        if(T is None): T = self.block_size\n",
        "        if(C is None): C = self.state_dim\n",
        "\n",
        "        k = self.key(global_pos_emb + state_emb + action_emb)   # (B,T,C)\n",
        "        #q = self.query(global_pos_emb + action_emb) # (B,T,C)\n",
        "        \n",
        "        # compute attention scores (\"affinities\") - C**-0.5 is for normalization\n",
        "        wei =  tf.matmul(k, tf.transpose(k, perm=[0, 2, 1])) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei *= tf.math.rsqrt(tf.cast(C, tf.float32))\n",
        "        wei = tf.where(tf.linalg.band_part(tf.ones((T, T)), -1, 0) == 0, tf.constant(float(\"-inf\"), shape=(B, T, T)), wei) # (B, T, T)\n",
        "        wei = tf.nn.softmax(wei, axis=-1) # (B, T, T)\n",
        "        # perform the weighted aggregation of the values\n",
        "\n",
        "        v = self.value(state_emb + action_emb) # (B,T,C)\n",
        "        out = tf.matmul(wei, v) # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        out = self.dropout_v(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        #state_emb = global_pos_emb = local_pos_emb = embedding_dim\n",
        "        state_emb, global_pos_emb, action_emb = input_shape\n",
        "        self.value.build(state_emb)\n",
        "        self.key.build(state_emb)\n",
        "        self.query.build(state_emb)\n",
        "        super(Head, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46rkRg5nqQdn"
      },
      "outputs": [],
      "source": [
        "# Layer with multiple self-attention Heads for data communication \n",
        "class MultiHeadAttention(Layer):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, batch_size, block_size, embedding_dim, num_heads, head_size, dropout):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.heads = []\n",
        "        for _ in range(num_heads):\n",
        "            head = Head(\n",
        "                batch_size=batch_size,\n",
        "                block_size=block_size,\n",
        "                head_size=head_size,\n",
        "                dropout=dropout,\n",
        "            )\n",
        "            head.build(((None, None, embedding_dim), (None, None, embedding_dim), (None, None, embedding_dim)))\n",
        "            self.heads.append(head)\n",
        "        \n",
        "        # this linear layer is used to 'merge' the multiple heads acquired knowledge\n",
        "        self.proj = Dense(units=embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        self.dropout = Dropout(dropout)\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        # concatenate the heads outputs in the C dimension\n",
        "        out =  tf.concat([h(inp) for h in self.heads], axis=-1)\n",
        "        # apply thE projection and dropout\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        super(MultiHeadAttention, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGMjfU_IqQdo"
      },
      "outputs": [],
      "source": [
        "#Simple feed forward for data computation\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, embedding_dim, dropout, resize_to_input_dim=True, spread_dim=None):\n",
        "        # resize_to_input_dim -> Should be False only to last block element when posterior computation is gonna happen so it doesn't need to output embedding_dim sized elements to another block\n",
        "        # spread_dim -> the heads output comes concatenated in sequence so is computed and joint by the spread layer layer\n",
        "        super().__init__()\n",
        "        last_layer = [\n",
        "            Dense(embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer()), \n",
        "            Dropout(dropout)\n",
        "        ] if resize_to_input_dim else []\n",
        "        \n",
        "        self.net = Sequential([\n",
        "            Dense(spread_dim if spread_dim is not None else 4 * embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer()),\n",
        "            Dropout(dropout),\n",
        "            *last_layer\n",
        "        ])\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnyFKuPEqQdp"
      },
      "outputs": [],
      "source": [
        "# Block containing a multi head attention module and a feed forward linear computation\n",
        "class Block(Layer):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "    def __init__(self, batch_size, block_size, emb_dim, num_heads, dropout, resize_to_input_dim=None, spread_dim=None):\n",
        "        super().__init__()\n",
        "        self.resize_to_input_dim = resize_to_input_dim\n",
        "        head_size = emb_dim // num_heads # each head gets a portion of the embeddings so different relations can be learned\n",
        "        \n",
        "        self.sa = MultiHeadAttention(batch_size, block_size, emb_dim, num_heads, head_size, dropout)\n",
        "\n",
        "        self.ffwd = FeedForward(emb_dim, dropout, resize_to_input_dim, spread_dim)\n",
        "        self.ffwd_ln = LayerNormalization()\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        st_emp, global_pos_emb, act_emb = inp[0], inp[1], inp[2]\n",
        "\n",
        "        # Multi head attention with layer norm\n",
        "        x = st_emp + self.sa([st_emp, global_pos_emb, act_emb])\n",
        "        \n",
        "        # feed forward with layer norm\n",
        "        ffw = self.ffwd(self.ffwd_ln(x))\n",
        "        x = (x + ffw) if self.resize_to_input_dim else ffw\n",
        "\n",
        "        return x\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        st_emb, global_pos_emb, act_emb = input_shape\n",
        "        self.ffwd_ln.build(st_emb)\n",
        "        self.sa.build(input_shape)\n",
        "        super(Block, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_value = lambda : RandomNormal(mean=0.0, stddev=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4uZbSagqQdq"
      },
      "outputs": [],
      "source": [
        "class GPTModel(Model):\n",
        "    def __init__(self, n_layer, batch_size, block_size, embedding_dim, out_dim, num_heads, dropout, ffw):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.state_embedding = Dense(units=embedding_dim, activation='sigmoid', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        self.action_embedding = Dense(units=embedding_dim, activation='sigmoid', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        \n",
        "        self.blocks = []\n",
        "        for i in range(n_layer):\n",
        "            block = Block(batch_size, block_size, embedding_dim, num_heads, dropout,\n",
        "                resize_to_input_dim = (i != n_layer - 1 ),  \n",
        "                spread_dim = out_dim if (i == n_layer - 1 ) else None,\n",
        "            )\n",
        "            block.build(((None, None, embedding_dim), (None, None, embedding_dim), (None, None, embedding_dim)))\n",
        "            self.blocks.append(block)\n",
        "\n",
        "        self.ffw = ffw\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def get_local_position_sin_encoding(self, batch_size, block_size, n=10000):\n",
        "        positions = np.tile([np.arange(block_size)], [batch_size, 1])\n",
        "        batch_size, block_size = positions.shape[:2]\n",
        "        aux = np.tile(np.tile([np.arange(self.embedding_dim)], [block_size, 1]), [batch_size, 1, 1])\n",
        "        denominator = tf.cast(n**((2*(aux//2))/self.embedding_dim), dtype=tf.float32)\n",
        "        val = tf.cast(np.tile(positions, [1, 1, self.embedding_dim]), dtype=tf.float32)\n",
        "        P = (np.sin(val/denominator) * ((aux + 1)%2)) + (np.cos(val/denominator)*(aux%2))\n",
        "        return P\n",
        "  \n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        states, global_positions, actions = inp[0], inp[1], inp[2]\n",
        "        B, T, C = states.shape\n",
        "        if(T is None): T = self.block_size\n",
        "        if(B is None): B = self.batch_size\n",
        "\n",
        "        #local_position = self.get_local_position_sin_encoding(batch_size=B, block_size=T)\n",
        "        act_emb = self.action_embedding(actions)\n",
        "        st_emb = self.state_embedding(states)\n",
        "        \n",
        "        for block in self.blocks: st_emb = block((st_emb, global_positions, act_emb))\n",
        "        logits = self.ffw(st_emb)\n",
        "\n",
        "        return logits\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def generate(self, states, positions, actions):\n",
        "        # crop idx to the last block_size tokens\n",
        "        st_cond = states[:, -self.block_size:, :]\n",
        "        pos_cond = positions[:, -self.block_size:, :]\n",
        "        act_cond = actions[:, -self.block_size:, :]\n",
        "        # get the predictions\n",
        "        actions = self([st_cond, pos_cond, act_cond])\n",
        "        # focus only on the last time step\n",
        "        return actions\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        states, positions, actions = input_shape\n",
        "        self.action_embedding.build(actions)\n",
        "        self.state_embedding.build(states)\n",
        "        super(GPTModel, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdauE0A-qQdr",
        "outputId": "f775f548-57dc-43a6-877b-8cf35079d9a6"
      },
      "outputs": [],
      "source": [
        "class Actor(object):\n",
        "    def __init__(self, n_layer, batch_size, block_size, state_dim, action_dim, embedding_dim, num_heads, dropout, action_range, lr):\n",
        "        #Network dimensions\n",
        "        self.inp_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        ffw = lambda: Sequential([\n",
        "            BatchNormalization(),\n",
        "            Dense(128, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Dropout(dropout),\n",
        "            BatchNormalization(),\n",
        "            Dense(32,  activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Dropout(dropout),\n",
        "            BatchNormalization(),\n",
        "            Dense(action_dim, activation='tanh', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Lambda(lambda i: i * action_range, dtype='float64'),\n",
        "        ]) \n",
        "\n",
        "        #Generates the optimization function - used in the agent to generate gradients\n",
        "        self.optimizer = Adam(lr)\n",
        "\n",
        "        #Generates the actor model\n",
        "        self.model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.model.build(((None, None, state_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "    #--------------------------------------------------------------------\n",
        "    def predict(self, states, positions, actions):\n",
        "        return self.model.generate(states, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def act(self, states, positions, actions):\n",
        "        action = self.predict(states, positions, actions)\n",
        "        # Gets the last action only\n",
        "        action = action[0, -1, :]\n",
        "        return action\n",
        "        \n",
        "    #--------------------------------------------------------------------\n",
        "    def saveModel(self, path):\n",
        "        self.model.save(path + '_actor_model.h5')\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def loadModel(self, path):\n",
        "        self.model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iws_SlRZqQds",
        "outputId": "30dfbb02-a02f-4373-fb58-8fd4db3b5774"
      },
      "outputs": [],
      "source": [
        "class Critic(object):\n",
        "    def __init__(self, n_layer, batch_size, block_size, state_dim, action_dim, embedding_dim, out_dim, num_heads, dropout, lr):\n",
        "        #Network dimensions\n",
        "        self.inp_dim = state_dim + action_dim\n",
        "        ffw = lambda: Sequential([\n",
        "                BatchNormalization(),\n",
        "                Dense(64, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "                Dropout(dropout),\n",
        "                BatchNormalization(),\n",
        "                Dense(32, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "                Dropout(dropout),\n",
        "                BatchNormalization(),\n",
        "                Dense(out_dim, activation='linear', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            ]) \n",
        "\n",
        "        #Generates the optimization function - used in the agent to generate gradients\n",
        "        self.optimizer = Adam(lr)\n",
        "\n",
        "        #Generates the actor model\n",
        "        self.model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.model.build(((None, None, self.inp_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def predict(self, states, next_actions, positions, actions):\n",
        "        states = tf.cast(states, tf.float32) \n",
        "        next_actions = tf.cast(next_actions, tf.float32) \n",
        "        positions = tf.cast(positions, tf.float32)\n",
        "        actions = tf.cast(actions, tf.float32)\n",
        "        inp = tf.concat([states, next_actions], 2)\n",
        "        return self.model.generate(inp, positions, actions)\n",
        "        \n",
        "    #--------------------------------------------------------------------\n",
        "    def saveModel(self, path):\n",
        "        self.model.save(path + '_critic_model.h5')\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def loadModel(self, path):\n",
        "        self.model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2y8GZ7tqQds"
      },
      "outputs": [],
      "source": [
        "class DDPG_GPT_Agent(object):\n",
        "    def __init__(self, a_n_layers, c_n_layers, batch_size, block_size, state_dim, action_dim, a_n_heads, c_n_heads, \n",
        "        dropout, action_min, action_max, memory_size, gamma, a_lr, c_lr, epsilon, epsilon_decay, \n",
        "        epsilon_min, a_embedding_dim, c_embedding_dim):\n",
        "        \n",
        "        self.block_size = block_size\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.action_min = action_min\n",
        "        self.action_max = action_max\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.a_embedding_dim = a_embedding_dim\n",
        "        self.c_embedding_dim = c_embedding_dim\n",
        "\n",
        "        self.episode_batch_size = batch_size\n",
        "        self.steps_batch_size = 1\n",
        "\n",
        "        #Creates the Replay Buffer\n",
        "        self.memory = ReplayBuffer(memory_size, self.episode_batch_size)\n",
        "\n",
        "        #Creates the noise generator\n",
        "        self.ou_noise = OUActionNoise(mean=np.zeros(action_dim))\n",
        "\n",
        "        #Creates the actor\n",
        "        self.actor = Actor(\n",
        "            n_layer=a_n_layers,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            state_dim=state_dim, \n",
        "            action_dim=action_dim, \n",
        "            embedding_dim=a_embedding_dim,\n",
        "            num_heads=a_n_heads, \n",
        "            dropout=dropout, \n",
        "            action_range=action_max, \n",
        "            lr=a_lr, \n",
        "        )\n",
        "        \n",
        "        #Creates the critic\n",
        "        self.critic = Critic(\n",
        "            n_layer=c_n_layers,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            state_dim=state_dim, \n",
        "            action_dim=action_dim, \n",
        "            embedding_dim=c_embedding_dim,\n",
        "            out_dim=1,\n",
        "            num_heads=c_n_heads, \n",
        "            dropout=dropout, \n",
        "            lr=c_lr, \n",
        "        )\n",
        "    \n",
        "    #--------------------------------------------------------------------     \n",
        "    def act(self, env):\n",
        "        action = np.zeros(self.action_dim)\n",
        "        state = env.reset()\n",
        "        step = np.array([1])\n",
        "\n",
        "        actions = action.reshape(1, 1, -1)\n",
        "        states = state.reshape(1, 1, -1)\n",
        "        positions = step.reshape(1, 1, -1)\n",
        "\n",
        "        done = False\n",
        "        while not done:\n",
        "            env.render()\n",
        "            action = self.policy(states, positions, actions, explore=False)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            step += 1\n",
        "\n",
        "            states = tf.concat((states, state.reshape(1, 1, -1)), axis=1)\n",
        "            positions = tf.concat((positions, np.array([step]).reshape(1, 1, -1)), axis=1)\n",
        "            actions = tf.concat((actions, action.reshape(1, 1, -1)), axis=1)\n",
        "        \n",
        "        return\n",
        "    \n",
        "    #-------------------------------------------------------------------- \n",
        "    def get_position_sin_encoding(self, embedding_dim, positions, n=10000):\n",
        "        batch_size, block_size = positions.shape[:2]\n",
        "        aux = np.tile(np.tile([np.arange(embedding_dim)], [block_size, 1]), [batch_size, 1, 1])\n",
        "        denominator = tf.cast(n**((2*(aux//2))/embedding_dim), dtype=tf.float32)\n",
        "        val = tf.cast(np.tile(positions, [1, 1, embedding_dim]), dtype=tf.float32)\n",
        "        P = (np.sin(val/denominator) * ((aux + 1)%2)) + (np.cos(val/denominator)*(aux%2))\n",
        "        return P\n",
        "\n",
        "    #-------------------------------------------------------------------- \n",
        "    def policy(self, states, positions, actions, explore=True):\n",
        "        \"\"\" Generates an action from a group of states and add exploration \"\"\"\n",
        "        # gets the action\n",
        "        action = self.actor.act(states, self.get_position_sin_encoding(self.a_embedding_dim, positions), actions)\n",
        "        # takes the exploration with the epsilon probability\n",
        "        if explore and np.random.rand() < self.epsilon: action += self.ou_noise()\n",
        "        # clip the action to be between min and max values\n",
        "        action = np.clip(action, a_min=self.action_min, a_max=self.action_max)\n",
        "        action[np.isnan(action)] = 0\n",
        "\n",
        "        return action   \n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def record_memories(self, steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        self.memory.append(steps)\n",
        "        return\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def learn(self, memory_steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        \"\"\" Append an experience to the memory and replay memory if possible \"\"\"\n",
        "        self.record_memories(memory_steps)\n",
        "        if self.memory.hasMinLength: self.replay_memory()\n",
        "        return\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def episode_to_batch(self, episode):\n",
        "        #episode = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        if len(episode) > (self.block_size + self.steps_batch_size):\n",
        "            steps_idxs = np.random.choice(np.arange(self.block_size, len(episode)), size=self.steps_batch_size-1, replace=False)\n",
        "            steps_idxs = np.append(steps_idxs, len(episode))\n",
        "        else: steps_idxs = np.arange(self.block_size, len(episode))\n",
        "        \n",
        "        batch = np.array([episode[i-self.block_size:i] for i in steps_idxs])\n",
        "        #batch = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        return batch\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def null_step(self, step):\n",
        "        #step = {'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}\n",
        "        step['reward'] = 0\n",
        "        step['done'] = True\n",
        "        return step\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def episode_pad(self, episode):\n",
        "        #episode = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        return np.concatenate((episode, [self.null_step(episode[-1]) for _ in range(self.block_size - len(episode) + 1)]))\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def get_episodes_batches(self, episodes):\n",
        "        #episodes = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        batch = None\n",
        "\n",
        "        join_episode = lambda final_value, aux_value: aux_value if final_value is None else np.concatenate((final_value, aux_value))\n",
        "\n",
        "        for episode in episodes:\n",
        "            if len(episode) <= self.block_size: episode = self.episode_pad(episode)\n",
        "            ep_batch = self.episode_to_batch(episode)\n",
        "            batch = join_episode(batch, ep_batch)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    #--------------------------------------------------------------------    \n",
        "    def replay_memory(self):\n",
        "        \"\"\" Replay a batch of memories \"\"\"\n",
        "\n",
        "        # Get sample block from the replay buffer\n",
        "        episodes = self.memory.getEpisodes()\n",
        "        batch = self.get_episodes_batches(episodes)\n",
        "        #batch = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        to_tensor = lambda value: tf.convert_to_tensor(value, dtype='float32')\n",
        "        get_batch_element = lambda key, batch: to_tensor([[step[key] for step in block] for block in batch])\n",
        "        \n",
        "        positions = tf.expand_dims(get_batch_element('step', batch), axis=-1)\n",
        "        next_positions_actor = self.get_position_sin_encoding(self.a_embedding_dim, positions + 1)\n",
        "        next_positions_critic = self.get_position_sin_encoding(self.c_embedding_dim, positions + 1)\n",
        "        positions_actor = self.get_position_sin_encoding(self.a_embedding_dim, positions)\n",
        "        positions_critic = self.get_position_sin_encoding(self.c_embedding_dim, positions)\n",
        "\n",
        "        states = get_batch_element('state', batch)\n",
        "        next_states = get_batch_element('next_state', batch)\n",
        "\n",
        "        prev_actions = get_batch_element('prev_action', batch)  \n",
        "        actions = get_batch_element('action', batch)\n",
        "\n",
        "        rewards = tf.expand_dims(get_batch_element('reward', batch), axis=-1)\n",
        "        done = tf.expand_dims(get_batch_element('done', batch), axis=-1)\n",
        "\n",
        "        #Train the critic\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Compute the actor target actions\n",
        "            target_actions = self.actor.predict(next_states, next_positions_actor, actions)\n",
        "            # Compute the critic target values \n",
        "            predicted_return = self.critic.predict(next_states, target_actions, next_positions_critic, actions)\n",
        "            # The return for the last block element\n",
        "            last_return = predicted_return[:, -1, :]\n",
        "\n",
        "            # Compute the gamma tensor based on the block step\n",
        "            gamma_values = lambda i: tf.expand_dims(tf.repeat([[self.gamma**(k - i+1) for k in range(i, rewards.shape[1]-1)]], repeats=rewards.shape[0], axis=0), axis=-1)\n",
        "            # Compute the gamma weighted reward for a given block step\n",
        "            weighted_next_rewards = lambda i: tf.math.reduce_sum(rewards[:, i+1:, :] * gamma_values(i), axis=1)\n",
        "            # The gamma weight for the last return bootstrap\n",
        "            last_return_weight = lambda i: self.gamma ** (rewards.shape[1] - i)\n",
        "            # Compute the done value for a block step\n",
        "            state_done = lambda i: 1 - done[:, i, :]\n",
        "            \n",
        "            # Compute the return target values\n",
        "            computed_returns = tf.stack([\n",
        "                *[((weighted_next_rewards(i) + (last_return_weight(i) * last_return * state_done(-1))) * state_done(i)) for i in range(rewards.shape[1]-1)], \n",
        "                tf.zeros([rewards.shape[0], 1]),\n",
        "            ], axis=1)\n",
        "            #bootstrapped_returns = self.gamma * predicted_return * (1 - done)\n",
        "            \n",
        "            y = rewards + computed_returns\n",
        "            # Predict the expected reward associated with taking the target predicted action in the state\n",
        "            critic_value = self.critic.predict(states, actions, positions_critic, prev_actions)\n",
        "            # Compute the critic loss  \n",
        "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
        "            \n",
        "        critic_grad = tape.gradient(critic_loss, self.critic.model.trainable_variables)\n",
        "        self.critic.optimizer.apply_gradients(\n",
        "            (grad, var) \n",
        "            for (grad, var) in zip(critic_grad, self.critic.model.trainable_variables) \n",
        "            if grad is not None\n",
        "        )\n",
        "        \n",
        "        #Train the actor\n",
        "        with tf.GradientTape() as tape:\n",
        "            acts = self.actor.predict(states, positions_actor, prev_actions)\n",
        "            critic_grads = self.critic.predict(states, acts, positions_critic, prev_actions)\n",
        "            #Used -mean as we want to maximize the value given by the critic for our actions\n",
        "            actor_loss = -tf.math.reduce_mean(critic_grads)\n",
        "\n",
        "        actor_grad = tape.gradient(actor_loss, self.actor.model.trainable_variables)\n",
        "        self.actor.optimizer.apply_gradients(\n",
        "            (grad, var) \n",
        "            for (grad, var) in zip(actor_grad, self.actor.model.trainable_variables)\n",
        "            if grad is not None\n",
        "        )\n",
        "        \n",
        "    #--------------------------------------------------\n",
        "    def print_data(self, verbose, episode, step, score):\n",
        "        if verbose:\n",
        "            print(\"\\r                                                                                                     \", end=\"\")\n",
        "            print(\"\\rEpisode: \"+str(episode+1)+\"\\t Step: \"+str(step)+\"\\tReward: \"+str(round(score, 2)) ,end=\"\")\n",
        "        return\n",
        "\n",
        "    #--------------------------------------------------------------------     \n",
        "    def train(self, env, num_episodes, step_per_train, verbose, verbose_num, end_on_complete=False, complete_num=1, complete_value=float('inf'), act_after_batch=False):\n",
        "        scores_history = []\n",
        "        steps_history = []\n",
        "        complete = 0\n",
        "        print(\"BEGIN\\n\")\n",
        "        \n",
        "        for episode in range(num_episodes):\n",
        "            done = False\n",
        "            score, step = 0, 1\n",
        "            state = env.reset()\n",
        "            prev_action = np.zeros(self.action_dim)\n",
        "\n",
        "            states = state.reshape(1, 1, -1)\n",
        "            positions = np.array([step]).reshape(1, 1, -1)\n",
        "            actions = prev_action.reshape(1, 1, -1)\n",
        "            \n",
        "            while not done:\n",
        "                memory_steps = []\n",
        "\n",
        "                for _ in range(step_per_train):\n",
        "                    action = self.policy(states, positions, actions)\n",
        "                    new_state, reward, done, info = env.step(action)\n",
        "                    self.print_data(verbose, episode, step, score)\n",
        "                    \n",
        "                    memory_steps.append({\n",
        "                        'step': step, \n",
        "                        'prev_action': prev_action, \n",
        "                        'state': state, \n",
        "                        'action':  action, \n",
        "                        'next_state': new_state, \n",
        "                        'reward': reward, \n",
        "                        'done':  int(done),\n",
        "                    })\n",
        "\n",
        "                    state = new_state\n",
        "                    prev_action = action\n",
        "                    step += 1\n",
        "                    score += reward\n",
        "\n",
        "                    states = tf.concat((states, new_state.reshape(1, 1, -1)), axis=1)\n",
        "                    positions = tf.concat((positions, np.array([step]).reshape(1, 1, -1)), axis=1)\n",
        "                    actions = tf.concat((actions, action.reshape(1, 1, -1)), axis=1)\n",
        "                    if done: break\n",
        "                \n",
        "                if len(memory_steps) > 0: self.learn(memory_steps)\n",
        "                self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)\n",
        "\n",
        "            scores_history.append(score)\n",
        "            steps_history.append(step)\n",
        "            \n",
        "            #If the score is bigger or equal than the complete score it add one to the completed number\n",
        "            if(score >= complete_value):\n",
        "                complete += 1\n",
        "                #If the flag is true the agent ends the trainig on the firs complete episode\n",
        "                if end_on_complete and complete >= complete_num: break\n",
        "            \n",
        "            #These information are printed after each verbose_num episodes\n",
        "            if((episode+1)%verbose_num == 0):\n",
        "                print(\"\\r                                                                                                          \", end=\"\")\n",
        "                print(\"\\rEpisodes: \", episode+1, \"/\", num_episodes, \n",
        "                      \"\\n\\tTotal reward: \", round(np.mean(scores_history[-verbose_num:]), 2), '+/-', round(np.std(scores_history[-verbose_num:]), 2), \n",
        "                      \"\\n\\tNum. steps: \", round(np.mean(steps_history[-verbose_num:]), 2), '+/-', round(np.std(steps_history[-verbose_num:]), 2), \n",
        "                      *[\"\\n\\tCompleted: \", complete] if complete_value != float('inf') else '', \n",
        "                      \"\\n--------------------------\",\n",
        "                    )\n",
        "                \n",
        "                #If the flag is true the agent act and render the episode after each verbose_num episodes\n",
        "                if act_after_batch: self.act(env)\n",
        "                \n",
        "                #Set the number of completed episodes on the batch to zero\n",
        "                complete = 0\n",
        "\n",
        "        print(\"\\nFINISHED\")\n",
        "        \n",
        "        return scores_history, steps_history\n",
        "    #--------------------------------------------------------------------     \n",
        "    def save(self, path):\n",
        "        self.actor.saveModel(path)\n",
        "        self.critic.saveModel(path)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def load(self, a_path, c_path):\n",
        "        self.actor.loadModel(a_path)\n",
        "        self.critic.loadModel(c_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wS8tg8OqQdt",
        "outputId": "3d5e1dc5-3b35-4c65-b236-f11b903b86d7",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"LunarLander-v2\", continuous=True)\n",
        "batch_size = 256\n",
        "block_size = 100\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "action_min = env.action_space.low\n",
        "action_max = env.action_space.high\n",
        "dropout = 0.05\n",
        "memory_size = 200\n",
        "gamma = 0.997\n",
        "\n",
        "epsilon = 1\n",
        "epsilon_decay = 0.9997\n",
        "epsilon_min = 0.3\n",
        "\n",
        "# Actor hyperparameter\n",
        "a_n_layer = 1\n",
        "a_num_heads = 1\n",
        "a_embedding_dim = 32\n",
        "a_learning_rate = 7e-5\n",
        "\n",
        "# Critic hyperparameter\n",
        "c_n_layer = 1\n",
        "c_num_heads = 1\n",
        "c_embedding_dim = 32\n",
        "c_learning_rate = 4e-4\n",
        "\n",
        "agent = DDPG_GPT_Agent(\n",
        "    a_n_layers = a_n_layer,\n",
        "    c_n_layers = c_n_layer, \n",
        "    batch_size = batch_size, \n",
        "    block_size=block_size, \n",
        "    state_dim=state_dim, \n",
        "    action_dim=action_dim, \n",
        "    a_embedding_dim=a_embedding_dim,\n",
        "    c_embedding_dim=c_embedding_dim,\n",
        "    a_n_heads=a_num_heads, \n",
        "    c_n_heads=c_num_heads,\n",
        "    dropout=dropout, \n",
        "    action_min=action_min, \n",
        "    action_max=action_max, \n",
        "    memory_size=memory_size, \n",
        "    gamma=gamma, \n",
        "    a_lr=a_learning_rate, \n",
        "    c_lr=c_learning_rate, \n",
        "    epsilon=epsilon, \n",
        "    epsilon_decay=epsilon_decay, \n",
        "    epsilon_min=epsilon_min,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aCvb6NiqQdu",
        "outputId": "bb989c21-13bb-441f-bc9a-179631844892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEGIN\n",
            "\n",
            "Episodes:  10 / 300                                                                                       \n",
            "\tTotal reward:  -522.34 +/- 211.98 \n",
            "\tNum. steps:  100.1 +/- 25.92 \n",
            "--------------------------\n",
            "Episodes:  20 / 300                                                                                       \n",
            "\tTotal reward:  -340.54 +/- 161.05 \n",
            "\tNum. steps:  77.4 +/- 24.23 \n",
            "--------------------------\n",
            "Episodes:  30 / 300                                                                                       \n",
            "\tTotal reward:  -135.91 +/- 37.03 \n",
            "\tNum. steps:  79.1 +/- 12.73 \n",
            "--------------------------\n",
            "Episodes:  40 / 300                                                                                       \n",
            "\tTotal reward:  -120.15 +/- 30.27 \n",
            "\tNum. steps:  75.7 +/- 15.85 \n",
            "--------------------------\n",
            "Episodes:  50 / 300                                                                                       \n",
            "\tTotal reward:  -142.05 +/- 26.56 \n",
            "\tNum. steps:  73.4 +/- 15.42 \n",
            "--------------------------\n",
            "Episodes:  60 / 300                                                                                       \n",
            "\tTotal reward:  -108.01 +/- 16.27 \n",
            "\tNum. steps:  69.0 +/- 9.79 \n",
            "--------------------------\n",
            "Episodes:  70 / 300                                                                                       \n",
            "\tTotal reward:  -108.25 +/- 12.65 \n",
            "\tNum. steps:  70.8 +/- 14.8 \n",
            "--------------------------\n",
            "Episodes:  80 / 300                                                                                       \n",
            "\tTotal reward:  -120.93 +/- 19.33 \n",
            "\tNum. steps:  80.2 +/- 13.08 \n",
            "--------------------------\n",
            "Episodes:  90 / 300                                                                                       \n",
            "\tTotal reward:  -119.24 +/- 20.08 \n",
            "\tNum. steps:  75.3 +/- 9.76 \n",
            "--------------------------\n",
            "Episodes:  100 / 300                                                                                      \n",
            "\tTotal reward:  -121.38 +/- 22.32 \n",
            "\tNum. steps:  74.4 +/- 12.49 \n",
            "--------------------------\n",
            "Episodes:  110 / 300                                                                                      \n",
            "\tTotal reward:  -118.79 +/- 15.63 \n",
            "\tNum. steps:  69.4 +/- 13.12 \n",
            "--------------------------\n",
            "Episodes:  120 / 300                                                                                      \n",
            "\tTotal reward:  -115.1 +/- 20.26 \n",
            "\tNum. steps:  74.1 +/- 13.87 \n",
            "--------------------------\n",
            "Episodes:  130 / 300                                                                                      \n",
            "\tTotal reward:  -115.73 +/- 19.58 \n",
            "\tNum. steps:  64.8 +/- 11.1 \n",
            "--------------------------\n",
            "Episodes:  140 / 300                                                                                      \n",
            "\tTotal reward:  -124.82 +/- 19.33 \n",
            "\tNum. steps:  67.9 +/- 8.79 \n",
            "--------------------------\n",
            "Episodes:  150 / 300                                                                                      \n",
            "\tTotal reward:  -114.15 +/- 15.04 \n",
            "\tNum. steps:  72.5 +/- 10.78 \n",
            "--------------------------\n",
            "Episodes:  160 / 300                                                                                      \n",
            "\tTotal reward:  -138.31 +/- 88.06 \n",
            "\tNum. steps:  84.8 +/- 21.4 \n",
            "--------------------------\n",
            "Episodes:  170 / 300                                                                                      \n",
            "\tTotal reward:  -98.43 +/- 49.88 \n",
            "\tNum. steps:  88.2 +/- 13.3 \n",
            "--------------------------\n",
            "Episodes:  180 / 300                                                                                      \n",
            "\tTotal reward:  -69.62 +/- 41.51 \n",
            "\tNum. steps:  88.2 +/- 14.76 \n",
            "--------------------------\n",
            "Episodes:  190 / 300                                                                                      \n",
            "\tTotal reward:  -114.77 +/- 143.23 \n",
            "\tNum. steps:  101.7 +/- 21.66 \n",
            "--------------------------\n",
            "Episodes:  200 / 300                                                                                      \n",
            "\tTotal reward:  -92.66 +/- 32.64 \n",
            "\tNum. steps:  118.6 +/- 64.38 \n",
            "--------------------------\n",
            "Episodes:  210 / 300                                                                                      \n",
            "\tTotal reward:  -125.89 +/- 117.13 \n",
            "\tNum. steps:  127.7 +/- 49.75 \n",
            "--------------------------\n",
            "Episodes:  220 / 300                                                                                      \n",
            "\tTotal reward:  -214.14 +/- 187.35 \n",
            "\tNum. steps:  172.1 +/- 87.13 \n",
            "--------------------------\n",
            "Episodes:  230 / 300                                                                                      \n",
            "\tTotal reward:  -180.62 +/- 94.91 \n",
            "\tNum. steps:  170.6 +/- 97.19 \n",
            "--------------------------\n",
            "Episodes:  240 / 300                                                                                      \n",
            "\tTotal reward:  -208.76 +/- 116.7 \n",
            "\tNum. steps:  144.5 +/- 85.45 \n",
            "--------------------------\n",
            "Episode: 246\t Step: 389\tReward: -32.74                                                               "
          ]
        }
      ],
      "source": [
        "num_episodes = 300\n",
        "step_per_train = 1\n",
        "verbose = True\n",
        "verbose_num = 10\n",
        "act_after_batch = True\n",
        "\n",
        "scores, steps = agent.train(\n",
        "    env=env, \n",
        "    num_episodes=num_episodes,\n",
        "    step_per_train=step_per_train,\n",
        "    verbose=verbose, \n",
        "    verbose_num=verbose_num,  \n",
        "    act_after_batch=act_after_batch,\n",
        ")\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f523fff1600>]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(scores)), scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f525727bb80>]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(steps)), steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", continuous=True)\n",
        "agent.act(env)\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
