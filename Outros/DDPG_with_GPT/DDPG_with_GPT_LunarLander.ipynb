{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8WT_0Y-KqQdW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout, BatchNormalization, LayerNormalization, Lambda\n",
        "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vQX1S3qQdc"
      },
      "source": [
        "# Objective: Create a DDPG algorithm with a GPT as the Actor network.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeO6YvRbqQdf",
        "outputId": "98286af3-47a0-4c4a-8c82-c041308ccc0c"
      },
      "outputs": [],
      "source": [
        "#Ornstein-Uhlenbeck Noise \n",
        "class OUActionNoise(object):\n",
        "    def __init__(self, mean, sigma=0.5, theta=0.2, dt=0.4, x0=None):\n",
        "        self.mean = mean\n",
        "        self.sigma = sigma\n",
        "        self.theta = theta\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.reset()\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "    #Method that enables to write classes where the instances behave like functions and can be called like a function.    \n",
        "    def __call__(self):\n",
        "        x = self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
        "        self.x_prev = x\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "    def reset(self):\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mean)\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-n5JPCPqQdi",
        "outputId": "a2773b70-2744-4aa3-c777-6acd96c63981"
      },
      "outputs": [],
      "source": [
        "#Replay Buffer \n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size, batch_size):\n",
        "        '''\n",
        "        Args:\n",
        "            size (integer): The size of the replay buffer.              \n",
        "            batch_size (integer): The batch size.\n",
        "            block_size (integer): \n",
        "        '''\n",
        "        self.buffer = [[]]\n",
        "        self.batch_size = batch_size\n",
        "        self.max_size = size\n",
        "        \n",
        "    #--------------------------------------------------    \n",
        "    def append(self, steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        if self.size >= self.max_size: del self.buffer[0]\n",
        "        for step in steps: self.buffer[-1].append(step)\n",
        "        # if done create new episode entry\n",
        "        # (state, action, reward, done)\n",
        "        if (steps[-1]['done']): self.buffer.append([])\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def clear(self):\n",
        "        self.buffer.clear()\n",
        "    \n",
        "    #--------------------------------------------------    \n",
        "    def getEpisodes(self):\n",
        "        episodes = np.random.choice(\n",
        "            np.arange(self.size - 1), #don't chose the current step\n",
        "            size=(self.batch_size,), \n",
        "            replace=True\n",
        "        )\n",
        "        return  [self.buffer[episode] for episode in episodes]\n",
        "    \n",
        "    #--------------------------------------------------  \n",
        "    @property  \n",
        "    def size(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            Number of elements in the buffer\n",
        "        '''\n",
        "        return len(self.buffer)\n",
        "\n",
        "    #--------------------------------------------------  \n",
        "    @property \n",
        "    def hasMinLength(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            Boolean indicating if the memory have the minimum number of elements or not\n",
        "        '''\n",
        "        return (self.size > 1)\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    @property  \n",
        "    def data(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            List with all the elements in the buffer\n",
        "        '''\n",
        "        return self.buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1en0TDn5qQdl",
        "outputId": "c485ce90-2d8c-4f0a-cc48-6efad0b8233c"
      },
      "outputs": [],
      "source": [
        "gpt_kernel_initializer = lambda: RandomNormal(mean=0.0, stddev=0.1)\n",
        "gpt_bias_initializer = lambda: Zeros()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vxHdLrUWqQdm"
      },
      "outputs": [],
      "source": [
        "# Individual Head of self-attention\n",
        "class Head(Layer):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, batch_size, block_size, head_size, dropout):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.block_size = block_size\n",
        "\n",
        "        # key, query and value layers\n",
        "        self.key = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "        self.query = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "        self.value = Dense(units=head_size, use_bias=False, kernel_initializer=gpt_kernel_initializer())\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout_v = Dropout(dropout)\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        state_emb, global_pos_emb, action_emb = inp[0], inp[1], inp[2]\n",
        "        B, T, C = state_emb.shape\n",
        "        if(B is None): B = self.batch_size \n",
        "        if(T is None): T = self.block_size\n",
        "        if(C is None): C = self.state_dim\n",
        "\n",
        "        k = self.key(global_pos_emb + action_emb)   # (B,T,C)\n",
        "        #q = self.query(global_pos_emb + action_emb) # (B,T,C)\n",
        "        \n",
        "        # compute attention scores (\"affinities\") - C**-0.5 is for normalization\n",
        "        wei =  tf.matmul(k, tf.transpose(k, perm=[0, 2, 1])) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei *= tf.math.rsqrt(tf.cast(C, tf.float32))\n",
        "        wei = tf.where(tf.linalg.band_part(tf.ones((T, T)), -1, 0) == 0, tf.constant(float(\"-inf\"), shape=(B, T, T)), wei) # (B, T, T)\n",
        "        wei = tf.nn.softmax(wei, axis=-1) # (B, T, T)\n",
        "        # perform the weighted aggregation of the values\n",
        "\n",
        "        v = self.value(state_emb + action_emb) # (B,T,C)\n",
        "        out = tf.matmul(wei, v) # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        out = self.dropout_v(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        #state_emb = global_pos_emb = local_pos_emb = embedding_dim\n",
        "        state_emb, global_pos_emb, action_emb = input_shape\n",
        "        self.value.build(state_emb)\n",
        "        self.key.build(state_emb)\n",
        "        self.query.build(state_emb)\n",
        "        super(Head, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "46rkRg5nqQdn"
      },
      "outputs": [],
      "source": [
        "# Layer with multiple self-attention Heads for data communication \n",
        "class MultiHeadAttention(Layer):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, batch_size, block_size, embedding_dim, num_heads, head_size, dropout):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.heads = []\n",
        "        for _ in range(num_heads):\n",
        "            head = Head(\n",
        "                batch_size=batch_size,\n",
        "                block_size=block_size,\n",
        "                head_size=head_size,\n",
        "                dropout=dropout,\n",
        "            )\n",
        "            head.build(((None, None, embedding_dim), (None, None, embedding_dim), (None, None, embedding_dim)))\n",
        "            self.heads.append(head)\n",
        "        \n",
        "        # this linear layer is used to 'merge' the multiple heads acquired knowledge\n",
        "        self.proj = Dense(units=embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        self.dropout = Dropout(dropout)\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        # concatenate the heads outputs in the C dimension\n",
        "        out =  tf.concat([h(inp) for h in self.heads], axis=-1)\n",
        "        # apply thE projection and dropout\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        super(MultiHeadAttention, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VGMjfU_IqQdo"
      },
      "outputs": [],
      "source": [
        "#Simple feed forward for data computation\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, embedding_dim, dropout, resize_to_input_dim=True, spread_dim=None):\n",
        "        # resize_to_input_dim -> Should be False only to last block element when posterior computation is gonna happen so it doesn't need to output embedding_dim sized elements to another block\n",
        "        # spread_dim -> the heads output comes concatenated in sequence so is computed and joint by the spread layer layer\n",
        "        super().__init__()\n",
        "        last_layer = [\n",
        "            Dense(embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer()), \n",
        "            Dropout(dropout)\n",
        "        ] if resize_to_input_dim else []\n",
        "        \n",
        "        self.net = Sequential([\n",
        "            Dense(spread_dim if spread_dim is not None else 4 * embedding_dim, activation='relu', kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer()),\n",
        "            Dropout(dropout),\n",
        "            *last_layer\n",
        "        ])\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "YnyFKuPEqQdp"
      },
      "outputs": [],
      "source": [
        "# Block containing a multi head attention module and a feed forward linear computation\n",
        "class Block(Layer):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "    def __init__(self, batch_size, block_size, emb_dim, num_heads, dropout, resize_to_input_dim=None, spread_dim=None):\n",
        "        super().__init__()\n",
        "        self.resize_to_input_dim = resize_to_input_dim\n",
        "        head_size = emb_dim // num_heads # each head gets a portion of the embeddings so different relations can be learned\n",
        "        \n",
        "        self.sa = MultiHeadAttention(batch_size, block_size, emb_dim, num_heads, head_size, dropout)\n",
        "        self.st_ln = LayerNormalization()\n",
        "        self.gp_ln = LayerNormalization()\n",
        "        self.ac_ln = LayerNormalization()\n",
        "\n",
        "        self.ffwd = FeedForward(emb_dim, dropout, resize_to_input_dim, spread_dim)\n",
        "        self.ffwd_ln = LayerNormalization()\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        st_emp, global_pos_emb, act_emb = inp[0], inp[1], inp[2]\n",
        "\n",
        "        # Multi head attention with layer norm\n",
        "        x = st_emp + self.sa([\n",
        "            self.st_ln(st_emp), \n",
        "            global_pos_emb, \n",
        "            self.ac_ln(act_emb),\n",
        "        ])\n",
        "        \n",
        "        # feed forward with layer norm\n",
        "        ffw = self.ffwd(self.ffwd_ln(x))\n",
        "        x = (x + ffw) if self.resize_to_input_dim else ffw\n",
        "\n",
        "        return x\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        st_emb, global_pos_emb, act_emb = input_shape\n",
        "        self.st_ln.build(st_emb)\n",
        "        self.gp_ln.build(global_pos_emb)\n",
        "        self.ac_ln.build(act_emb)\n",
        "        self.ffwd_ln.build(st_emb)\n",
        "        super(Block, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_value = lambda : RandomNormal(mean=0.0, stddev=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "V4uZbSagqQdq"
      },
      "outputs": [],
      "source": [
        "class GPTModel(Model):\n",
        "    def __init__(self, n_layer, batch_size, block_size, embedding_dim, out_dim, num_heads, dropout, ffw):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.state_embedding = Dense(units=embedding_dim, kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        self.action_embedding = Dense(units=embedding_dim, kernel_initializer=gpt_kernel_initializer(), bias_initializer=gpt_bias_initializer())\n",
        "        \n",
        "        self.blocks = []\n",
        "        for i in range(n_layer):\n",
        "            block = Block(batch_size, block_size, embedding_dim, num_heads, dropout,\n",
        "                resize_to_input_dim = (i != n_layer - 1 ),  \n",
        "                spread_dim = out_dim if (i == n_layer - 1 ) else None,\n",
        "            )\n",
        "            block.build(((None, None, embedding_dim), (None, None, embedding_dim), (None, None, embedding_dim)))\n",
        "            self.blocks.append(block)\n",
        "\n",
        "        self.ffw = ffw\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def get_local_position_sin_encoding(self, batch_size, block_size, n=10000):\n",
        "        positions = np.tile([np.arange(block_size)], [batch_size, 1])\n",
        "        batch_size, block_size = positions.shape[:2]\n",
        "        aux = np.tile(np.tile([np.arange(self.embedding_dim)], [block_size, 1]), [batch_size, 1, 1])\n",
        "        denominator = tf.cast(n**((2*(aux//2))/self.embedding_dim), dtype=tf.float32)\n",
        "        val = tf.cast(np.tile(positions, [1, 1, self.embedding_dim]), dtype=tf.float32)\n",
        "        P = (np.sin(val/denominator) * ((aux + 1)%2)) + (np.cos(val/denominator)*(aux%2))\n",
        "        return P\n",
        "  \n",
        "    #--------------------------------------------------\n",
        "    def call(self, inp, training=False):\n",
        "        states, global_positions, actions = inp[0], inp[1], inp[2]\n",
        "        B, T, C = states.shape\n",
        "        if(T is None): T = self.block_size\n",
        "        if(B is None): B = self.batch_size\n",
        "\n",
        "        #local_position = self.get_local_position_sin_encoding(batch_size=B, block_size=T)\n",
        "        act_emb = self.action_embedding(actions)\n",
        "        st_emb = self.state_embedding(states)\n",
        "        \n",
        "        for block in self.blocks: st_emb = block((st_emb, global_positions, act_emb))\n",
        "        logits = self.ffw(st_emb)\n",
        "\n",
        "        return logits\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def generate(self, states, positions, actions):\n",
        "        # crop idx to the last block_size tokens\n",
        "        st_cond = states[:, -self.block_size:, :]\n",
        "        pos_cond = positions[:, -self.block_size:, :]\n",
        "        act_cond = actions[:, -self.block_size:, :]\n",
        "        # get the predictions\n",
        "        actions = self([st_cond, pos_cond, act_cond])\n",
        "        # focus only on the last time step\n",
        "        return actions\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def build(self, input_shape):\n",
        "        states, positions, actions = input_shape\n",
        "        self.action_embedding.build(actions)\n",
        "        self.state_embedding.build(states)\n",
        "        super(GPTModel, self).build((len(input_shape), None, None, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdauE0A-qQdr",
        "outputId": "f775f548-57dc-43a6-877b-8cf35079d9a6"
      },
      "outputs": [],
      "source": [
        "class Actor(object):\n",
        "    def __init__(self, n_layer, batch_size, block_size, state_dim, action_dim, embedding_dim, num_heads, dropout, action_range, lr, tau):\n",
        "        #Network dimensions\n",
        "        self.inp_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        ffw = lambda: Sequential([\n",
        "            Dense(16, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Dropout(dropout),\n",
        "            Dense(action_dim, activation='tanh', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            Lambda(lambda i: i * action_range, dtype='float64'),\n",
        "        ]) \n",
        "\n",
        "        #Parameter that coordinates the soft updates on the target weights\n",
        "        self.tau = tau\n",
        "\n",
        "        #Generates the optimization function - used in the agent to generate gradients\n",
        "        self.optimizer = Adam(lr)\n",
        "\n",
        "        #Generates the actor model\n",
        "        self.model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.model.build(((None, None, state_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Generates the actor target model\n",
        "        self.target_model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.target_model.build(((None, None, state_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Set the weights to be the same in the begining\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def predict(self, states, positions, actions):\n",
        "        return self.model.generate(states, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def target_predict(self, states, positions, actions):\n",
        "        return self.target_model.generate(states, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def act(self, states, positions, actions):\n",
        "        action = self.predict(states, positions, actions)\n",
        "        # Gets the last action only\n",
        "        action = action[0, -1, :]\n",
        "        return action\n",
        "\n",
        "    #--------------------------------------------------------------------\n",
        "    def transferWeights(self):\n",
        "        weights = self.model.get_weights()\n",
        "        target_weights = self.target_model.get_weights()\n",
        "        new_weights = []\n",
        "        \n",
        "        for i in range(len(weights)):\n",
        "            new_weights.append((self.tau * weights[i]) + ((1.0 - self.tau) * target_weights[i]))\n",
        "        \n",
        "        self.target_model.set_weights(new_weights)\n",
        "        \n",
        "    #--------------------------------------------------------------------\n",
        "    def saveModel(self, path):\n",
        "        self.model.save(path + '_actor_model.h5')\n",
        "        self.target_model.save(path + '_actor_target_model.h5')\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def loadModel(self, path):\n",
        "        self.target_model = load_model(path)\n",
        "        self.model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iws_SlRZqQds",
        "outputId": "30dfbb02-a02f-4373-fb58-8fd4db3b5774"
      },
      "outputs": [],
      "source": [
        "class Critic(object):\n",
        "    def __init__(self, n_layer, batch_size, block_size, state_dim, action_dim, embedding_dim, out_dim, num_heads, dropout, lr, tau):\n",
        "        #Network dimensions\n",
        "        self.inp_dim = state_dim + action_dim\n",
        "        ffw = lambda: Sequential([\n",
        "                Dense(8, activation='relu', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "                Dropout(dropout),\n",
        "                Dense(out_dim, activation='linear', kernel_initializer=f_value(), bias_initializer=f_value()),\n",
        "            ]) \n",
        "\n",
        "        #Parameter that coordinates the soft updates on the target weights\n",
        "        self.tau = tau\n",
        "\n",
        "        #Generates the optimization function - used in the agent to generate gradients\n",
        "        self.optimizer = Adam(lr)\n",
        "\n",
        "        #Generates the actor model\n",
        "        self.model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.model.build(((None, None, self.inp_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Generates the actor target model\n",
        "        self.target_model = GPTModel(\n",
        "            n_layer=n_layer,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            embedding_dim=embedding_dim, \n",
        "            out_dim=256,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            ffw = ffw(),\n",
        "        )\n",
        "        self.target_model.build(((None, None, self.inp_dim), (None, None, embedding_dim), (None, None, action_dim)))\n",
        "\n",
        "        #Set the weights to be the same in the begining\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def predict(self, states, next_actions, positions, actions):\n",
        "        states = tf.cast(states, tf.float32) \n",
        "        next_actions = tf.cast(next_actions, tf.float32) \n",
        "        positions = tf.cast(positions, tf.float32)\n",
        "        actions = tf.cast(actions, tf.float32)\n",
        "        inp = tf.concat([states, next_actions], 2)\n",
        "        return self.model.generate(inp, positions, actions)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def target_predict(self, states, next_actions, positions, actions):\n",
        "        states = tf.cast(states, tf.float32) \n",
        "        next_actions = tf.cast(next_actions, tf.float32) \n",
        "        positions = tf.cast(positions, tf.float32)\n",
        "        actions = tf.cast(actions, tf.float32)\n",
        "        inp = tf.concat([states, next_actions], 2)\n",
        "        return self.target_model.generate(inp, positions, actions)\n",
        "    \n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def transferWeights(self):\n",
        "        weights = self.model.get_weights()\n",
        "        target_weights = self.target_model.get_weights()\n",
        "        new_weights = []\n",
        "        \n",
        "        for i in range(len(weights)):\n",
        "            new_weights.append((self.tau * weights[i]) + ((1.0 - self.tau) * target_weights[i]))\n",
        "        \n",
        "        self.target_model.set_weights(new_weights)\n",
        "        \n",
        "    #--------------------------------------------------------------------\n",
        "    def saveModel(self, path):\n",
        "        self.model.save(path + '_critic_model.h5')\n",
        "        self.target_model.save(path + '_critic_target_model.h5')\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def loadModel(self, path):\n",
        "        self.target_model = load_model(path)\n",
        "        self.model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "n2y8GZ7tqQds"
      },
      "outputs": [],
      "source": [
        "class DDPG_GPT_Agent(object):\n",
        "    def __init__(self, a_n_layers, c_n_layers, batch_size, block_size, state_dim, action_dim, a_n_heads, c_n_heads, \n",
        "        dropout, action_min, action_max, memory_size, gamma, a_lr, c_lr, tau, epsilon, epsilon_decay, \n",
        "        epsilon_min, a_embedding_dim, c_embedding_dim):\n",
        "        \n",
        "        self.block_size = block_size\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.action_min = action_min\n",
        "        self.action_max = action_max\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.a_embedding_dim = a_embedding_dim\n",
        "        self.c_embedding_dim = c_embedding_dim\n",
        "\n",
        "        self.episode_batch_size = batch_size\n",
        "        self.steps_batch_size = 1\n",
        "\n",
        "        #Creates the Replay Buffer\n",
        "        self.memory = ReplayBuffer(memory_size, self.episode_batch_size)\n",
        "\n",
        "        #Creates the noise generator\n",
        "        self.ou_noise = OUActionNoise(mean=np.zeros(action_dim))\n",
        "\n",
        "        #Creates the actor\n",
        "        self.actor = Actor(\n",
        "            n_layer=a_n_layers,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            state_dim=state_dim, \n",
        "            action_dim=action_dim, \n",
        "            embedding_dim=a_embedding_dim,\n",
        "            num_heads=a_n_heads, \n",
        "            dropout=dropout, \n",
        "            action_range=action_max, \n",
        "            lr=a_lr, \n",
        "            tau=tau,\n",
        "        )\n",
        "        \n",
        "        #Creates the critic\n",
        "        self.critic = Critic(\n",
        "            n_layer=c_n_layers,\n",
        "            batch_size=batch_size, \n",
        "            block_size=block_size, \n",
        "            state_dim=state_dim, \n",
        "            action_dim=action_dim, \n",
        "            embedding_dim=c_embedding_dim,\n",
        "            out_dim=1,\n",
        "            num_heads=c_n_heads, \n",
        "            dropout=dropout, \n",
        "            lr=c_lr, \n",
        "            tau=tau,\n",
        "        )\n",
        "    \n",
        "    #--------------------------------------------------------------------     \n",
        "    def act(self, env):\n",
        "        action = np.zeros(self.action_dim)\n",
        "        state = env.reset()\n",
        "        step = np.array([1])\n",
        "\n",
        "        actions = action.reshape(1, 1, -1)\n",
        "        states = state.reshape(1, 1, -1)\n",
        "        positions = step.reshape(1, 1, -1)\n",
        "\n",
        "        done = False\n",
        "        while not done:\n",
        "            env.render()\n",
        "            action = self.policy(states, positions, actions, explore=False)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            step += 1\n",
        "\n",
        "            states = tf.concat((states, state.reshape(1, 1, -1)), axis=1)\n",
        "            positions = tf.concat((positions, np.array([step]).reshape(1, 1, -1)), axis=1)\n",
        "            actions = tf.concat((actions, action.reshape(1, 1, -1)), axis=1)\n",
        "        \n",
        "        return\n",
        "    \n",
        "    #-------------------------------------------------------------------- \n",
        "    def get_position_sin_encoding(self, embedding_dim, positions, n=10000):\n",
        "        batch_size, block_size = positions.shape[:2]\n",
        "        aux = np.tile(np.tile([np.arange(embedding_dim)], [block_size, 1]), [batch_size, 1, 1])\n",
        "        denominator = tf.cast(n**((2*(aux//2))/embedding_dim), dtype=tf.float32)\n",
        "        val = tf.cast(np.tile(positions, [1, 1, embedding_dim]), dtype=tf.float32)\n",
        "        P = (np.sin(val/denominator) * ((aux + 1)%2)) + (np.cos(val/denominator)*(aux%2))\n",
        "        return P\n",
        "\n",
        "    #-------------------------------------------------------------------- \n",
        "    def policy(self, states, positions, actions, explore=True):\n",
        "        \"\"\" Generates an action from a group of states and add exploration \"\"\"\n",
        "        # gets the action\n",
        "        action = self.actor.act(states, self.get_position_sin_encoding(self.a_embedding_dim, positions), actions)\n",
        "        # takes the exploration with the epsilon probability\n",
        "        if explore and np.random.rand() < self.epsilon: action += self.ou_noise()\n",
        "        # clip the action to be between min and max values\n",
        "        action = np.clip(action, a_min=self.action_min, a_max=self.action_max)\n",
        "        action[np.isnan(action)] = 0\n",
        "\n",
        "        return action   \n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def record_memories(self, steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        self.memory.append(steps)\n",
        "        return\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def learn(self, memory_steps):\n",
        "        # steps = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        \"\"\" Append an experience to the memory and replay memory if possible \"\"\"\n",
        "        self.record_memories(memory_steps)\n",
        "        if self.memory.hasMinLength: self.replay_memory()\n",
        "        return\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def episode_to_batch(self, episode):\n",
        "        #episode = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        if len(episode) > (self.block_size + self.steps_batch_size):\n",
        "            steps_idxs = np.random.choice(np.arange(self.block_size, len(episode)), size=self.steps_batch_size-1, replace=False)\n",
        "            steps_idxs = np.append(steps_idxs, len(episode))\n",
        "        else: steps_idxs = np.arange(self.block_size, len(episode))\n",
        "        \n",
        "        batch = np.array([episode[i-self.block_size:i] for i in steps_idxs])\n",
        "        #batch = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        return batch\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def null_step(self, step):\n",
        "        #step = {'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}\n",
        "        step['reward'] = 0\n",
        "        step['done'] = True\n",
        "        return step\n",
        "\n",
        "    #--------------------------------------------------\n",
        "    def episode_pad(self, episode):\n",
        "        #episode = [{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]\n",
        "        return np.concatenate((episode, [self.null_step(episode[-1]) for _ in range(self.block_size - len(episode) + 1)]))\n",
        "    \n",
        "    #--------------------------------------------------\n",
        "    def get_episodes_batches(self, episodes):\n",
        "        #episodes = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        batch = None\n",
        "\n",
        "        join_episode = lambda final_value, aux_value: aux_value if final_value is None else np.concatenate((final_value, aux_value))\n",
        "\n",
        "        for episode in episodes:\n",
        "            if len(episode) <= self.block_size: episode = self.episode_pad(episode)\n",
        "            ep_batch = self.episode_to_batch(episode)\n",
        "            batch = join_episode(batch, ep_batch)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    #--------------------------------------------------------------------    \n",
        "    def replay_memory(self):\n",
        "        \"\"\" Replay a batch of memories \"\"\"\n",
        "\n",
        "        # Get sample block from the replay buffer\n",
        "        episodes = self.memory.getEpisodes()\n",
        "        batch = self.get_episodes_batches(episodes)\n",
        "        #batch = [[{'step': int, 'prev_action': [action_dim], 'state': [state_dim], 'action':  [action_dim], 'next_state': [state_dim], 'reward': float, 'done': boolean}]]\n",
        "        to_tensor = lambda value: tf.convert_to_tensor(value, dtype='float32')\n",
        "        get_batch_element = lambda key, batch: to_tensor([[step[key] for step in block] for block in batch])\n",
        "        \n",
        "        positions = tf.expand_dims(get_batch_element('step', batch), axis=-1)\n",
        "        next_positions_actor = self.get_position_sin_encoding(self.a_embedding_dim, positions + 1)\n",
        "        next_positions_critic = self.get_position_sin_encoding(self.c_embedding_dim, positions + 1)\n",
        "        positions_actor = self.get_position_sin_encoding(self.a_embedding_dim, positions)\n",
        "        positions_critic = self.get_position_sin_encoding(self.c_embedding_dim, positions)\n",
        "\n",
        "        states = get_batch_element('state', batch)\n",
        "        next_states = get_batch_element('next_state', batch)\n",
        "\n",
        "        prev_actions = get_batch_element('prev_action', batch)  \n",
        "        actions = get_batch_element('action', batch)\n",
        "\n",
        "        rewards = tf.expand_dims(get_batch_element('reward', batch), axis=-1)\n",
        "        done = tf.expand_dims(get_batch_element('done', batch), axis=-1)\n",
        "\n",
        "        #Train the critic\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Compute the actor target actions\n",
        "            target_actions = self.actor.target_predict(next_states, next_positions_actor, actions)\n",
        "            # Compute the critic target values \n",
        "            predicted_return = self.critic.target_predict(next_states, target_actions, next_positions_critic, actions)\n",
        "            # The return for the last block element\n",
        "            last_return = predicted_return[:, -1, :]\n",
        "\n",
        "            # Compute the gamma tensor based on the block step\n",
        "            gamma_values = lambda i: tf.expand_dims(tf.repeat([[self.gamma**(k - i+1) for k in range(i, rewards.shape[1]-1)]], repeats=rewards.shape[0], axis=0), axis=-1)\n",
        "            # Compute the gamma weighted reward for a given block step\n",
        "            weighted_next_rewards = lambda i: tf.math.reduce_sum(rewards[:, i+1:, :] * gamma_values(i), axis=1)\n",
        "            # The gamma weight for the last return bootstrap\n",
        "            last_return_weight = lambda i: self.gamma ** (rewards.shape[1] - i)\n",
        "            # Compute the done value for a block step\n",
        "            state_done = lambda i: 1 - done[:, i, :]\n",
        "            \n",
        "            # Compute the return target values\n",
        "            computed_returns = tf.stack([\n",
        "                *[((weighted_next_rewards(i) + (last_return_weight(i) * last_return * state_done(-1))) * state_done(i)) for i in range(rewards.shape[1]-1)], \n",
        "                tf.zeros([rewards.shape[0], 1]),\n",
        "            ], axis=1)\n",
        "            #bootstrapped_returns = self.gamma * predicted_return * (1 - done)\n",
        "            \n",
        "            y = rewards + computed_returns\n",
        "            # Predict the expected reward associated with taking the target predicted action in the state\n",
        "            critic_value = self.critic.predict(states, actions, positions_critic, prev_actions)\n",
        "            # Compute the critic loss  \n",
        "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
        "            \n",
        "        critic_grad = tape.gradient(critic_loss, self.critic.model.trainable_variables)\n",
        "        self.critic.optimizer.apply_gradients(\n",
        "            (grad, var) \n",
        "            for (grad, var) in zip(critic_grad, self.critic.model.trainable_variables) \n",
        "            if grad is not None\n",
        "        )\n",
        "        \n",
        "        #Train the actor\n",
        "        with tf.GradientTape() as tape:\n",
        "            acts = self.actor.predict(states, positions_actor, prev_actions)\n",
        "            critic_grads = self.critic.predict(states, acts, positions_critic, prev_actions)\n",
        "            #Used -mean as we want to maximize the value given by the critic for our actions\n",
        "            actor_loss = -tf.math.reduce_mean(critic_grads)\n",
        "\n",
        "        actor_grad = tape.gradient(actor_loss, self.actor.model.trainable_variables)\n",
        "        self.actor.optimizer.apply_gradients(\n",
        "            (grad, var) \n",
        "            for (grad, var) in zip(actor_grad, self.actor.model.trainable_variables)\n",
        "            if grad is not None\n",
        "        )\n",
        "            \n",
        "        #Update the model weights\n",
        "        self.actor.transferWeights()\n",
        "        self.critic.transferWeights() \n",
        "        \n",
        "    #--------------------------------------------------\n",
        "    def print_data(self, verbose, episode, step, score):\n",
        "        if verbose:\n",
        "            print(\"\\r                                                                                                     \", end=\"\")\n",
        "            print(\"\\rEpisode: \"+str(episode+1)+\"\\t Step: \"+str(step)+\"\\tReward: \"+str(round(score, 2)) ,end=\"\")\n",
        "        return\n",
        "\n",
        "    #--------------------------------------------------------------------     \n",
        "    def train(self, env, num_episodes, step_per_train, verbose, verbose_num, end_on_complete=False, complete_num=1, complete_value=float('inf'), act_after_batch=False):\n",
        "        scores_history = []\n",
        "        steps_history = []\n",
        "        complete = 0\n",
        "        print(\"BEGIN\\n\")\n",
        "        \n",
        "        for episode in range(num_episodes):\n",
        "            done = False\n",
        "            score, step = 0, 1\n",
        "            state = env.reset()\n",
        "            prev_action = np.zeros(self.action_dim)\n",
        "\n",
        "            states = state.reshape(1, 1, -1)\n",
        "            positions = np.array([step]).reshape(1, 1, -1)\n",
        "            actions = prev_action.reshape(1, 1, -1)\n",
        "            \n",
        "            while not done:\n",
        "                memory_steps = []\n",
        "\n",
        "                for _ in range(step_per_train):\n",
        "                    action = self.policy(states, positions, actions)\n",
        "                    new_state, reward, done, _ = env.step(action)\n",
        "                    self.print_data(verbose, episode, step, score)\n",
        "                    \n",
        "                    memory_steps.append({\n",
        "                        'step': step, \n",
        "                        'prev_action': prev_action, \n",
        "                        'state': state, \n",
        "                        'action':  action, \n",
        "                        'next_state': new_state, \n",
        "                        'reward': reward, \n",
        "                        'done':  int(done),\n",
        "                    })\n",
        "\n",
        "                    state = new_state\n",
        "                    prev_action = action\n",
        "                    step += 1\n",
        "                    score += reward\n",
        "\n",
        "                    states = tf.concat((states, new_state.reshape(1, 1, -1)), axis=1)\n",
        "                    positions = tf.concat((positions, np.array([step]).reshape(1, 1, -1)), axis=1)\n",
        "                    actions = tf.concat((actions, action.reshape(1, 1, -1)), axis=1)\n",
        "                    if done: break\n",
        "                \n",
        "                if len(memory_steps) > 0: self.learn(memory_steps)\n",
        "                self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)\n",
        "\n",
        "            scores_history.append(score)\n",
        "            steps_history.append(step)\n",
        "            \n",
        "            #If the score is bigger or equal than the complete score it add one to the completed number\n",
        "            if(score >= complete_value):\n",
        "                complete += 1\n",
        "                #If the flag is true the agent ends the trainig on the firs complete episode\n",
        "                if end_on_complete and complete >= complete_num: break\n",
        "            \n",
        "            #These information are printed after each verbose_num episodes\n",
        "            if((episode+1)%verbose_num == 0):\n",
        "                print(\"\\r                                                                                                          \", end=\"\")\n",
        "                print(\"\\rEpisodes: \", episode+1, \"/\", num_episodes, \n",
        "                      \"\\n\\tTotal reward: \", round(np.mean(scores_history[-verbose_num:]), 2), '+/-', round(np.std(scores_history[-verbose_num:]), 2), \n",
        "                      \"\\n\\tNum. steps: \", round(np.mean(steps_history[-verbose_num:]), 2), '+/-', round(np.std(steps_history[-verbose_num:]), 2), \n",
        "                      *[\"\\n\\tCompleted: \", complete] if complete_value != float('inf') else '', \n",
        "                      \"\\n--------------------------\",\n",
        "                    )\n",
        "                \n",
        "                #If the flag is true the agent act and render the episode after each verbose_num episodes\n",
        "                if act_after_batch: self.act(env)\n",
        "                \n",
        "                #Set the number of completed episodes on the batch to zero\n",
        "                complete = 0\n",
        "\n",
        "        print(\"\\nFINISHED\")\n",
        "        \n",
        "        return scores_history, steps_history\n",
        "    #--------------------------------------------------------------------     \n",
        "    def save(self, path):\n",
        "        self.actor.saveModel(path)\n",
        "        self.critic.saveModel(path)\n",
        "    \n",
        "    #--------------------------------------------------------------------\n",
        "    def load(self, a_path, c_path):\n",
        "        self.actor.loadModel(a_path)\n",
        "        self.critic.loadModel(c_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wS8tg8OqQdt",
        "outputId": "3d5e1dc5-3b35-4c65-b236-f11b903b86d7",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", continuous=True, max_episode_steps=1000)\n",
        "batch_size = 32\n",
        "block_size = 64\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "action_min = env.action_space.low\n",
        "action_max = env.action_space.high\n",
        "dropout = 0.05\n",
        "memory_size = 200\n",
        "gamma = 0.98\n",
        "\n",
        "epsilon = 1\n",
        "epsilon_decay = 0.9995\n",
        "epsilon_min = 0.1\n",
        "\n",
        "tau = 8e-4\n",
        "\n",
        "# Actor hyperparameter\n",
        "a_n_layer = 2\n",
        "a_num_heads = 1\n",
        "a_embedding_dim = 8\n",
        "a_learning_rate = 1e-4\n",
        "\n",
        "# Critic hyperparameter\n",
        "c_n_layer = 1\n",
        "c_num_heads = 2\n",
        "c_embedding_dim = 12\n",
        "c_learning_rate = 5e-4\n",
        "\n",
        "agent = DDPG_GPT_Agent(\n",
        "    a_n_layers = a_n_layer,\n",
        "    c_n_layers = c_n_layer, \n",
        "    batch_size = batch_size, \n",
        "    block_size=block_size, \n",
        "    state_dim=state_dim, \n",
        "    action_dim=action_dim, \n",
        "    a_embedding_dim=a_embedding_dim,\n",
        "    c_embedding_dim=c_embedding_dim,\n",
        "    a_n_heads=a_num_heads, \n",
        "    c_n_heads=c_num_heads,\n",
        "    dropout=dropout, \n",
        "    action_min=action_min, \n",
        "    action_max=action_max, \n",
        "    memory_size=memory_size, \n",
        "    gamma=gamma, \n",
        "    a_lr=a_learning_rate, \n",
        "    c_lr=c_learning_rate, \n",
        "    tau=tau, \n",
        "    epsilon=epsilon, \n",
        "    epsilon_decay=epsilon_decay, \n",
        "    epsilon_min=epsilon_min,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aCvb6NiqQdu",
        "outputId": "bb989c21-13bb-441f-bc9a-179631844892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEGIN\n",
            "\n",
            "Episodes:  10 / 500                                                                                       \n",
            "\tTotal reward:  -463.74 +/- 178.72 \n",
            "\tNum. steps:  93.9 +/- 20.38 \n",
            "--------------------------\n",
            "Episodes:  20 / 500                                                                                       \n",
            "\tTotal reward:  -379.43 +/- 348.17 \n",
            "\tNum. steps:  145.0 +/- 71.09 \n",
            "--------------------------\n",
            "Episodes:  30 / 500                                                                                       \n",
            "\tTotal reward:  -329.34 +/- 226.75 \n",
            "\tNum. steps:  144.2 +/- 98.19 \n",
            "--------------------------\n",
            "Episodes:  40 / 500                                                                                       \n",
            "\tTotal reward:  -162.01 +/- 46.34 \n",
            "\tNum. steps:  71.8 +/- 13.85 \n",
            "--------------------------\n",
            "Episodes:  50 / 500                                                                                       \n",
            "\tTotal reward:  -190.93 +/- 55.4 \n",
            "\tNum. steps:  75.7 +/- 17.33 \n",
            "--------------------------\n",
            "Episodes:  60 / 500                                                                                       \n",
            "\tTotal reward:  -134.24 +/- 29.91 \n",
            "\tNum. steps:  78.4 +/- 14.13 \n",
            "--------------------------\n",
            "Episodes:  70 / 500                                                                                       \n",
            "\tTotal reward:  -118.74 +/- 49.65 \n",
            "\tNum. steps:  99.5 +/- 28.53 \n",
            "--------------------------\n",
            "Episodes:  80 / 500                                                                                       \n",
            "\tTotal reward:  -132.76 +/- 54.07 \n",
            "\tNum. steps:  103.1 +/- 34.75 \n",
            "--------------------------\n",
            "Episodes:  90 / 500                                                                                       \n",
            "\tTotal reward:  -135.51 +/- 104.35 \n",
            "\tNum. steps:  126.0 +/- 43.69 \n",
            "--------------------------\n",
            "Episodes:  100 / 500                                                                                      \n",
            "\tTotal reward:  -249.47 +/- 109.31 \n",
            "\tNum. steps:  113.2 +/- 46.19 \n",
            "--------------------------\n",
            "Episodes:  110 / 500                                                                                      \n",
            "\tTotal reward:  -178.21 +/- 92.94 \n",
            "\tNum. steps:  116.5 +/- 49.32 \n",
            "--------------------------\n",
            "Episodes:  120 / 500                                                                                      \n",
            "\tTotal reward:  -144.03 +/- 88.17 \n",
            "\tNum. steps:  122.6 +/- 49.31 \n",
            "--------------------------\n",
            "Episodes:  130 / 500                                                                                      \n",
            "\tTotal reward:  -159.4 +/- 66.37 \n",
            "\tNum. steps:  100.1 +/- 34.23 \n",
            "--------------------------\n",
            "Episodes:  140 / 500                                                                                      \n",
            "\tTotal reward:  -142.55 +/- 83.01 \n",
            "\tNum. steps:  88.6 +/- 18.19 \n",
            "--------------------------\n",
            "Episodes:  150 / 500                                                                                      \n",
            "\tTotal reward:  -144.39 +/- 77.64 \n",
            "\tNum. steps:  97.8 +/- 32.69 \n",
            "--------------------------\n",
            "Episodes:  160 / 500                                                                                      \n",
            "\tTotal reward:  -173.54 +/- 45.44 \n",
            "\tNum. steps:  107.6 +/- 45.8 \n",
            "--------------------------\n",
            "Episodes:  170 / 500                                                                                      \n",
            "\tTotal reward:  -114.71 +/- 146.38 \n",
            "\tNum. steps:  121.0 +/- 32.46 \n",
            "--------------------------\n",
            "Episodes:  180 / 500                                                                                      \n",
            "\tTotal reward:  -178.7 +/- 49.66 \n",
            "\tNum. steps:  92.0 +/- 28.02 \n",
            "--------------------------\n",
            "Episodes:  190 / 500                                                                                      \n",
            "\tTotal reward:  -190.66 +/- 108.53 \n",
            "\tNum. steps:  81.5 +/- 26.66 \n",
            "--------------------------\n",
            "Episodes:  200 / 500                                                                                      \n",
            "\tTotal reward:  -168.31 +/- 59.13 \n",
            "\tNum. steps:  85.7 +/- 30.14 \n",
            "--------------------------\n",
            "Episodes:  210 / 500                                                                                      \n",
            "\tTotal reward:  -163.31 +/- 54.06 \n",
            "\tNum. steps:  80.8 +/- 19.18 \n",
            "--------------------------\n",
            "Episodes:  220 / 500                                                                                      \n",
            "\tTotal reward:  -201.12 +/- 127.83 \n",
            "\tNum. steps:  78.0 +/- 17.2 \n",
            "--------------------------\n",
            "Episodes:  230 / 500                                                                                      \n",
            "\tTotal reward:  -167.18 +/- 67.48 \n",
            "\tNum. steps:  81.6 +/- 17.89 \n",
            "--------------------------\n",
            "Episodes:  240 / 500                                                                                      \n",
            "\tTotal reward:  -213.73 +/- 169.98 \n",
            "\tNum. steps:  100.3 +/- 18.49 \n",
            "--------------------------\n",
            "Episodes:  250 / 500                                                                                      \n",
            "\tTotal reward:  -120.77 +/- 73.18 \n",
            "\tNum. steps:  95.3 +/- 25.25 \n",
            "--------------------------\n",
            "Episodes:  260 / 500                                                                                      \n",
            "\tTotal reward:  -194.12 +/- 127.61 \n",
            "\tNum. steps:  123.0 +/- 65.72 \n",
            "--------------------------\n",
            "Episodes:  270 / 500                                                                                      \n",
            "\tTotal reward:  -183.13 +/- 125.26 \n",
            "\tNum. steps:  114.3 +/- 56.63 \n",
            "--------------------------\n",
            "Episodes:  280 / 500                                                                                      \n",
            "\tTotal reward:  -144.31 +/- 116.34 \n",
            "\tNum. steps:  119.5 +/- 94.82 \n",
            "--------------------------\n",
            "Episodes:  290 / 500                                                                                      \n",
            "\tTotal reward:  -422.37 +/- 243.67 \n",
            "\tNum. steps:  189.5 +/- 149.25 \n",
            "--------------------------\n",
            "Episodes:  300 / 500                                                                                      \n",
            "\tTotal reward:  -233.25 +/- 86.3 \n",
            "\tNum. steps:  153.7 +/- 65.2 \n",
            "--------------------------\n",
            "Episodes:  310 / 500                                                                                      \n",
            "\tTotal reward:  -326.33 +/- 375.18 \n",
            "\tNum. steps:  139.2 +/- 81.91 \n",
            "--------------------------\n",
            "Episodes:  320 / 500                                                                                      \n",
            "\tTotal reward:  -358.14 +/- 355.31 \n",
            "\tNum. steps:  146.0 +/- 52.1 \n",
            "--------------------------\n",
            "Episodes:  330 / 500                                                                                      \n",
            "\tTotal reward:  -573.53 +/- 658.12 \n",
            "\tNum. steps:  169.4 +/- 107.53 \n",
            "--------------------------\n",
            "Episodes:  340 / 500                                                                                      \n",
            "\tTotal reward:  -277.4 +/- 94.58 \n",
            "\tNum. steps:  136.0 +/- 39.34 \n",
            "--------------------------\n",
            "Episodes:  350 / 500                                                                                      \n",
            "\tTotal reward:  -384.4 +/- 108.75 \n",
            "\tNum. steps:  159.6 +/- 51.88 \n",
            "--------------------------\n",
            "Episodes:  360 / 500                                                                                      \n",
            "\tTotal reward:  -305.75 +/- 148.81 \n",
            "\tNum. steps:  127.2 +/- 46.27 \n",
            "--------------------------\n",
            "Episodes:  370 / 500                                                                                      \n",
            "\tTotal reward:  -274.82 +/- 143.91 \n",
            "\tNum. steps:  117.5 +/- 35.12 \n",
            "--------------------------\n",
            "Episodes:  380 / 500                                                                                      \n",
            "\tTotal reward:  -238.29 +/- 173.89 \n",
            "\tNum. steps:  116.7 +/- 33.98 \n",
            "--------------------------\n",
            "Episodes:  390 / 500                                                                                      \n",
            "\tTotal reward:  -130.37 +/- 91.42 \n",
            "\tNum. steps:  128.6 +/- 48.77 \n",
            "--------------------------\n",
            "Episodes:  400 / 500                                                                                      \n",
            "\tTotal reward:  -178.85 +/- 52.4 \n",
            "\tNum. steps:  120.8 +/- 38.52 \n",
            "--------------------------\n",
            "Episodes:  410 / 500                                                                                      \n",
            "\tTotal reward:  -167.98 +/- 49.92 \n",
            "\tNum. steps:  100.9 +/- 35.51 \n",
            "--------------------------\n",
            "Episodes:  420 / 500                                                                                      \n",
            "\tTotal reward:  -178.47 +/- 67.16 \n",
            "\tNum. steps:  141.0 +/- 41.88 \n",
            "--------------------------\n",
            "Episodes:  430 / 500                                                                                      \n",
            "\tTotal reward:  -151.27 +/- 72.06 \n",
            "\tNum. steps:  109.0 +/- 33.67 \n",
            "--------------------------\n",
            "Episodes:  440 / 500                                                                                      \n",
            "\tTotal reward:  -152.76 +/- 77.63 \n",
            "\tNum. steps:  109.9 +/- 36.18 \n",
            "--------------------------\n",
            "Episodes:  450 / 500                                                                                      \n",
            "\tTotal reward:  -187.98 +/- 35.76 \n",
            "\tNum. steps:  108.9 +/- 26.83 \n",
            "--------------------------\n",
            "Episodes:  460 / 500                                                                                      \n",
            "\tTotal reward:  -191.66 +/- 39.06 \n",
            "\tNum. steps:  97.3 +/- 31.12 \n",
            "--------------------------\n",
            "Episodes:  470 / 500                                                                                      \n",
            "\tTotal reward:  -180.3 +/- 46.06 \n",
            "\tNum. steps:  120.4 +/- 49.24 \n",
            "--------------------------\n",
            "Episodes:  480 / 500                                                                                      \n",
            "\tTotal reward:  -160.73 +/- 63.52 \n",
            "\tNum. steps:  123.2 +/- 58.59 \n",
            "--------------------------\n",
            "Episodes:  490 / 500                                                                                      \n",
            "\tTotal reward:  -139.33 +/- 100.72 \n",
            "\tNum. steps:  137.2 +/- 46.59 \n",
            "--------------------------\n",
            "Episodes:  500 / 500                                                                                      \n",
            "\tTotal reward:  -176.83 +/- 62.91 \n",
            "\tNum. steps:  121.3 +/- 35.33 \n",
            "--------------------------\n",
            "\n",
            "FINISHED\n"
          ]
        }
      ],
      "source": [
        "num_episodes = 500\n",
        "step_per_train = 1\n",
        "verbose = True\n",
        "verbose_num = 10\n",
        "act_after_batch = True\n",
        "\n",
        "scores, steps = agent.train(\n",
        "    env=env, \n",
        "    num_episodes=num_episodes,\n",
        "    step_per_train=step_per_train,\n",
        "    verbose=verbose, \n",
        "    verbose_num=verbose_num,  \n",
        "    act_after_batch=act_after_batch,\n",
        ")\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcc41863340>]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(scores)), scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcc41973b20>]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(steps)), steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", continuous=True)\n",
        "agent.act(env)\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
