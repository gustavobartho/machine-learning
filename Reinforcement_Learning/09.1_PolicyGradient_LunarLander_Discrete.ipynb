{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import gym\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size, minibatch_size = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size (integer): The size of the replay buffer.              \n",
    "            minibatch_size (integer): The sample size.\n",
    "        \"\"\"\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState()\n",
    "        self.max_size = size\n",
    "    #--------------------------------------------------------------------------------    \n",
    "\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state (Numpy array): The state.              \n",
    "            action (integer): The action.\n",
    "            reward (float): The reward.\n",
    "            done (boolen): True if the next state is a terminal state and False otherwise.\n",
    "                           Is transformed to integer so tha True = 1, False = 0\n",
    "            next_state (Numpy array): The next state.           \n",
    "        \"\"\"\n",
    "        if self.size() == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        self.buffer.append([state, action, reward, next_state, int(done)])\n",
    "    #--------------------------------------------------------------------------------    \n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A list of transition tuples including state, action, reward, terminal, and next_state\n",
    "        \"\"\"\n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "    #--------------------------------------------------------------------------------    \n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            Number of elements in the buffer\n",
    "        \"\"\"\n",
    "        return len(self.buffer)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    \n",
    "    def min_full(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            Boolean indicating if the memory have the minimum number of elements or not\n",
    "        '''\n",
    "        return (self.size() >= self.minibatch_size)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    def empties(self):\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    def get_episode(self):\n",
    "        return self.buffer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, alpha, gamma, input_dims, layer1_size, layer2_size, n_actions, memory_size):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.G = 0\n",
    "        self.input_dims = input_dims\n",
    "        self.layer1_size = layer1_size\n",
    "        self.layer2_size = layer2_size\n",
    "        self.n_actions = n_actions\n",
    "        self.memory = ReplayBuffer(memory_size)\n",
    "        \n",
    "        self.policy, self.predict = self.build_policy_network(alpha, input_dims, layer1_size, layer2_size, n_actions)\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    def build_policy_network(self, alpha, input_dims, l1_size, l2_size, n_actions):\n",
    "        input_layer = Input(shape=(input_dims, ))\n",
    "        advantages = Input(shape=[1])\n",
    "        dense1 = Dense(l1_size, activation='relu')(input_layer)\n",
    "        dense2 = Dense(l2_size, activation='relu')(dense1)\n",
    "        probs = Dense(n_actions, activation='softmax')(dense2)\n",
    "        \n",
    "        def custom_loss(y_true, y_pred):\n",
    "            out = K.clip(y_pred, 1e-8, 1-1e-8)\n",
    "            log_lik = y_true*K.log(out)\n",
    "            \n",
    "            return K.sum(-log_lik*advantages)\n",
    "        \n",
    "        policy = Model(inputs=[input_layer, advantages], outputs=[probs])\n",
    "        policy.compile(optimizer=Adam(lr=alpha), loss=custom_loss)\n",
    "        \n",
    "        predict = Model(inputs=[input_layer], outputs=[probs])\n",
    "        \n",
    "        return policy, predict\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    def choose_action(self, observation):\n",
    "        state = observation[np.newaxis, :]\n",
    "        probabilities = self.predict.predict(state)[0]\n",
    "        action = np.random.choice(np.arange(self.n_actions), p=probabilities)\n",
    "        \n",
    "        one_hot_action = np.zeros(self.n_actions)\n",
    "        one_hot_action[action] = 1.\n",
    "        \n",
    "        return action, one_hot_action\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append(state, action, reward, next_state, done)\n",
    "        \n",
    "    #-----------------------------------------------------------------------------------------------    \n",
    "    def learn(self):\n",
    "        experiences = self.memory.get_episode()\n",
    "        states = np.array([exp[0] for exp in experiences])\n",
    "        actions = np.array([exp[1] for exp in experiences])\n",
    "        rewards = np.array([exp[2] for exp in experiences])\n",
    "        \n",
    "        G = np.zeros_like(rewards)\n",
    "        \n",
    "        for t in range(len(G)):\n",
    "            G_sum = 0\n",
    "            discount = 1\n",
    "            for k in range(t, len(G)):\n",
    "                G_sum += rewards[k]*discount\n",
    "                discount *= self.gamma\n",
    "            \n",
    "            G[t] = G_sum\n",
    "            \n",
    "        mean = np.mean(G)\n",
    "        std = np.std(G) if np.std(G) > 0 else 1\n",
    "        self.G = (G - mean)/std\n",
    "        \n",
    "        cost = self.policy.train_on_batch([states, self.G], actions)\n",
    "        \n",
    "        self.memory.empties()\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------   \n",
    "    def train(self, env, num_episodes, verbose, finish_limit, finish_ratio=1):\n",
    "        \n",
    "        scores_history = []\n",
    "        steps_history = []\n",
    "        \n",
    "        print(\"BEGIN\\n\")\n",
    "        complete = 0\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            done = False\n",
    "            score = 0\n",
    "            steps = 0\n",
    "            observation = env.reset()\n",
    "\n",
    "            while not done:\n",
    "                print(\"\\r                                                                                         \", end=\"\")\n",
    "                print(\"\\rEpisode: \"+str(episode+1)+\"\\tStep: \"+str(steps)+\"\\tReward: \"+str(score), end=\"\")\n",
    "                action, one_hot_action = self.choose_action(observation)\n",
    "                new_observation, reward, done, _ = env.step(action)\n",
    "                self.remember(observation, one_hot_action, reward, new_observation, done)\n",
    "                observation = new_observation\n",
    "                score += reward\n",
    "                steps += 1\n",
    "\n",
    "            self.learn()\n",
    "\n",
    "            if(score >= finish_limit):\n",
    "                complete += 1\n",
    "\n",
    "            if((episode+1)%verbose == 0):\n",
    "                print(\"\\r                                                                                         \", end=\"\")\n",
    "                print(\"\\rEpisodes: \", episode+1, \"/\", num_episodes\n",
    "                      , \"\\n\\tTotal reward: \", np.mean(scores_history[-verbose:])\n",
    "                      , \"\\n\\tNum. steps: \", np.mean(steps_history[-verbose:])\n",
    "                      , \"\\n\\tCompleted: \", complete, \"\\n--------------------------\\n\")\n",
    "                \n",
    "                if(complete >= finish_ratio*verbose):\n",
    "                    scores_history.append(score)\n",
    "                    steps_history.append(steps)\n",
    "                    break\n",
    "\n",
    "                complete = 0\n",
    "\n",
    "\n",
    "            scores_history.append(score)\n",
    "            steps_history.append(steps)\n",
    "\n",
    "        print(\"\\nFINISHED\")\n",
    "        \n",
    "        return scores_history, steps_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "\n",
      "Episodes:  250 / 5000                                                                    \n",
      "\tTotal reward:  -144.87934836531466 \n",
      "\tNum. steps:  104.30522088353413 \n",
      "\tCompleted:  0 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  500 / 5000                                                                    \n",
      "\tTotal reward:  -109.01960870955224 \n",
      "\tNum. steps:  170.1 \n",
      "\tCompleted:  0 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  750 / 5000                                                                    \n",
      "\tTotal reward:  -39.50626010775345 \n",
      "\tNum. steps:  274.268 \n",
      "\tCompleted:  0 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  1000 / 5000                                                                   \n",
      "\tTotal reward:  21.248208884841745 \n",
      "\tNum. steps:  539.196 \n",
      "\tCompleted:  0 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  1250 / 5000                                                                   \n",
      "\tTotal reward:  79.6018808508122 \n",
      "\tNum. steps:  773.856 \n",
      "\tCompleted:  0 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  1500 / 5000                                                                   \n",
      "\tTotal reward:  87.94642646116178 \n",
      "\tNum. steps:  752.12 \n",
      "\tCompleted:  0 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  1750 / 5000                                                                   \n",
      "\tTotal reward:  80.39136914859264 \n",
      "\tNum. steps:  664.344 \n",
      "\tCompleted:  5 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  2000 / 5000                                                                   \n",
      "\tTotal reward:  101.90387494286128 \n",
      "\tNum. steps:  716.292 \n",
      "\tCompleted:  20 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  2250 / 5000                                                                   \n",
      "\tTotal reward:  127.16169848126353 \n",
      "\tNum. steps:  590.572 \n",
      "\tCompleted:  91 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  2500 / 5000                                                                   \n",
      "\tTotal reward:  128.40189077231474 \n",
      "\tNum. steps:  655.712 \n",
      "\tCompleted:  66 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  2750 / 5000                                                                   \n",
      "\tTotal reward:  124.91305638148299 \n",
      "\tNum. steps:  850.396 \n",
      "\tCompleted:  14 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  3000 / 5000                                                                   \n",
      "\tTotal reward:  95.52236834563155 \n",
      "\tNum. steps:  558.484 \n",
      "\tCompleted:  13 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  3250 / 5000                                                                   \n",
      "\tTotal reward:  124.19985274321922 \n",
      "\tNum. steps:  754.004 \n",
      "\tCompleted:  27 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  3500 / 5000                                                                   \n",
      "\tTotal reward:  135.73999802612985 \n",
      "\tNum. steps:  599.484 \n",
      "\tCompleted:  63 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  3750 / 5000                                                                   \n",
      "\tTotal reward:  91.19250610737755 \n",
      "\tNum. steps:  407.596 \n",
      "\tCompleted:  39 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  4000 / 5000                                                                   \n",
      "\tTotal reward:  58.35237703552911 \n",
      "\tNum. steps:  252.86 \n",
      "\tCompleted:  43 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  4250 / 5000                                                                   \n",
      "\tTotal reward:  96.25032254950008 \n",
      "\tNum. steps:  467.444 \n",
      "\tCompleted:  52 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  4500 / 5000                                                                   \n",
      "\tTotal reward:  125.50135774056004 \n",
      "\tNum. steps:  518.5 \n",
      "\tCompleted:  75 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  4750 / 5000                                                                   \n",
      "\tTotal reward:  137.1843326107639 \n",
      "\tNum. steps:  668.96 \n",
      "\tCompleted:  59 \n",
      "--------------------------\n",
      "\n",
      "Episodes:  5000 / 5000                                                                   \n",
      "\tTotal reward:  146.06217811815117 \n",
      "\tNum. steps:  747.824 \n",
      "\tCompleted:  51 \n",
      "--------------------------\n",
      "\n",
      "\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "alpha = 5e-4\n",
    "gamma = 0.99\n",
    "input_dims = env.observation_space.shape[0]\n",
    "layer1_size = 128\n",
    "layer2_size = 64\n",
    "n_actions = env.action_space.n\n",
    "memory_size = 1100\n",
    "num_episodes = 5000\n",
    "verbose = 250\n",
    "\n",
    "agent = Agent(alpha, gamma, input_dims, layer1_size, layer2_size, n_actions, memory_size)\n",
    "\n",
    "scores, steps = agent.train(env, num_episodes, verbose, finish_limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "done = False\n",
    "cont = 0\n",
    "while not done:\n",
    "    env.render()\n",
    "    time.sleep(0.02)\n",
    "    if cont <= 0:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action, _ = agent.choose_action(observation)\n",
    "    new_observation, reward, done, _ = env.step(action)\n",
    "    observation = new_observation\n",
    "    cont += 1\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe401b27a50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = np.arange(num_episodes)\n",
    "plt.plot(t, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
